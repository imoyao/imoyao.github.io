<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何使 Pycharm 使用远程的 Flask 虚拟开发环境？]]></title>
    <url>%2Fblog%2F2019-05-06%2Fpycharm-with-remote-flask-venv%2F</url>
    <content type="text"><![CDATA[学习Flask开发的时候，因为主机是Windows环境，而日常跑服务的是Linux环境，所以需要通过配置pycharm使之使用远端的虚拟环境。 创建虚拟机Flask环境略 此处在网上可以找到很多写好的教程，不需要我再次叠床架屋了。 配置Pycharm环境打开Pycharm的setting对话框，按照如下配置 依次输入真实远端信息之后，点击下一步，直到出现下方对话框 依次修改将要使用的解释器和主机与远端需要保持同步的目录； 如图设置之后运行，Run出现如下结果 FLASK_APP = app FLASK_ENV = development FLASK_DEBUG = 1 In folder D:/MYcode/flk ssh://root@192.168.116.21:22/home/imoyao/envs/flk/bin/python -u -m flask run --host=0.0.0.0 * Serving Flask app &quot;app&quot; (lazy loading) * Environment: development * Debug mode: on * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger PIN: 820-491-228 之后在本机访问虚拟机ip，比如本例中的192.168.116.21:5000，即可进入app首页。 参考链接 配置flask服务进行调试 配置Python解释器]]></content>
      <categories>
        <category>工作日常</category>
      </categories>
      <tags>
        <tag>HOWTO</tag>
        <tag>PyCharm</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python传值还是传引用？| 通过对象引用传递]]></title>
    <url>%2Fblog%2F2019-04-13%2Fpython-pass-by-object-reference%2F</url>
    <content type="text"><![CDATA[哈姆雷特不是莎士比亚写的;它只是由一个名叫莎士比亚的人写的。Python 通过对象引用传递。 本文译自 Is Python pass-by-reference or pass-by-value? “假设我对 Fat 说，或 Kevin 对 Fat 说，“你没有经历过上帝。你只不过经历了一些与上帝的品质、方面、性质、力量、智慧和善良有关的事情。”这就像是关于德国人讲的一个双重抽象倾向的笑话；德国英国文学权威宣称，“哈姆雷特不是莎士比亚写的;它只是由一个名叫莎士比亚的人写的。”在英语语境中，这句话的区别只是口头的，没有实际意义，尽管德语中这种表达存在差异（这解释了德国思想的一些奇怪特征）。” –Valis，p71（Book-of-the-Month-Club Edition） Philip K. Dick并不以其轻松或易懂的散文而闻名。绝大多数角色都很高。就像，真的，真的，真的很高。然而，在Valis的上述引文（1981年出版）中，他对臭名昭着的Python参数传递范式给出了非常有远见的解释。Plus ça change, plus c’est omnomnomnom drugs. 在编程语言中参数传递的两种最广为人知且易于理解的方法是按引用传递( pass-by-reference )和按值传递 ( pass-by-value )。不幸的是，Python是“传递对象引用”( pass-by-object-reference )，经常说： “对象引用按值传递。”(Object references are passed by value.) 当我第一次看到这个沾沾自喜和过于精辟的定义时，我想捶人。在从手上取下玻璃碎片并被护送出脱衣舞俱乐部后，我意识到所有3种范例都可以理解它们如何导致以下2个功能的表现： def reassign(alist): alist = [0, 1] def append(alist): alist.append(1) alist = [0] reassign(alist) append(alist) 让我们来一探究竟。 变量不是对象“哈姆雷特不是莎士比亚写的;它只是由一个名叫莎士比亚的人写的。” Python 和 PKD（ Philip K. Dick）都在一个东西的本质与我们用来指代那个东西的标签之间做出了至关重要的区分。 “这个名叫莎士比亚的男人”是一个具体的人。 而“莎士比亚”只是一个名字。如果我们这样做： a = [] []是一个空列表。 a是指向空列表的变量，但其本身并不是空列表。我画图并将变量称为包含对象的“盒子”;但无论如何你构想它，这种差异是关键。 通过引用传递在pass-by-reference中，box（变量）直接传递给函数，其内容（由变量表示的对象）隐性地随之而来。在函数上下文中，参数本质上是调用者传入的变量的完整别名。它们都是完全相同的盒子，因此也指向内存中完全相同的对象。 因此，函数对变量或它所代表的对象所做的任何操作都将对调用者可见。例如，该函数可以完全更改变量的内容，并将其指向完全不同的对象： 该函数还可以在不重新分配对象的情况下操作对象，效果相同： 重申一下，在pass-by-reference中，函数和调用者都使用完全相同的变量和对象。 通过值传递在pass-by-value中，函数接收调用者传递给它的参数对象的副本，并在内存中开辟新的空间保存。 然后，该函数有效地提供其自己的盒子以将值放入，并且函数和调用者引用的变量或对象之间不再存在任何关系。这些对象碰巧具有相同的值，但它们完全是分开的，一个对象不会影响到另一个。如果我们再次尝试重新分配： 在函数之外，没有任何反应。同理： 调用者上下文中的变量和对象的副本是完全隔离的。 通过对象引用传递在Python是不同的。众所周知，在Python中，“对象引用按值传递”（Object references are passed by value）。 函数接收对（并将访问）内存中与调用者使用的相同对象的引用。但是，它不会收到调用者正在存储此对象的盒子;在pass-by-value中，函数提供自己的筐并为自己创建一个新变量。让我们再次执行append： 函数和调用者都引用内存中的同一个对象，所以当append函数向列表中添加一个额外的项时，我们也会在调用者中看到这个！它们是同一个东西的不同名称;包含相同对象的不同筐。这意味着是通过值传递对象引用的——函数和调用者在内存中使用相同的对象，但是通过不同的变量访问。这意味着同一个对象被存储在多个不同的筐中，而这种隐喻会被打破。假定它是量子或其他东西。 但关键是它们真的是不同的名字和不同的盒子。在pass-by-reference中，它们是相同的盒子。当你试图重新分配一个变量，并将一些不同的东西放入函数的盒子中时，你也将它放入调用者的盒子中，因为它们是同一个盒子。但是，在pass-by-object-reference中： 调用者不在乎你是否重新分配方法的盒子。不同的盒子，相同的内容。 现在我们看看菲利普·K·迪克试图告诉我们的事情。名字和人是不同的东西。变量和对象是不同的东西。有了这些知识，你或许可以开始推断当你做这样的事情时会发生什么 listA = [0] listB = listA listB.append(1) print listA 你可能还想了解这些概念与可变和不可变类型之间的有趣交互。但这些是另一回事了。现在，如果你能原谅我，我要去读《Dororoids Dream Of Electric Sheep？》了。 - 我对元编程有点生疏。 Does Python pass by reference or value? 参考链接： http://foobarnbaz.com/2012/07/08/understanding-python-variables/ http://javadude.com/articles/passbyvalue.htm]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下如何安装Redis？]]></title>
    <url>%2Fblog%2F2019-04-11%2Fhow-to-install-Redis-on-Linux%2F</url>
    <content type="text"><![CDATA[Redis是一款高性能的key-value数据库，本文主要记录如何在Linux系统上进行安装，以及为Python开发安装对应的redis模块。 测试环境 Linux版本 Ubuntu 18.04 LTS &amp;&amp; NeoKylin 3.2 Python版本 Python 2.7.15rc1 &amp;&amp; Python 2.6.6 Redis版本 redis-5.0.4 redis-py版本 redis-3.2.1 &amp;&amp; redis-2.10.6 下载下载地址：http://redis.io/download，下载最新稳定版本源码。 本文使用的版本为 redis-5.0.4。 安装Ubuntu 解压缩 首先要解压Redis压缩包。进入压缩包下载的路径，执行： tar xzf redis-5.0.4.tar.gz 使用GCC编译源码 cd redis-5.0.4 make 安装Redis make install 验证 root@local:~/temp# redis-server -v Redis server v=5.0.4 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=3dcf53963ddc396a root@local:~/temp# whereis redis-server redis-server: /usr/local/bin/redis-server 至此，Redis安装完成。 CentOs 编译安装 make $$ make install 此时报错 CC adlist.o /bin/sh: cc: command not found make[1]: *** [adlist.o] Error 127 make[1]: Leaving directory `/root/temp/redis-5.0.4/src&#39; make: *** [all] Error 2 安装gcc yum install gcc -y 重新make make 此时报错 In file included from adlist.c:34: zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory zmalloc.h:55:2: error: #error &quot;Newer version of jemalloc required&quot; make[1]: *** [adlist.o] Error 1 make[1]: Leaving directory `/root/temp/redis-5.0.4/src&#39; make: *** [all] Error 2 在构建Redis时选择非默认内存分配器是通过设置MALLOC环境变量完成的， 默认情况下Redis是使用malloc为libc编译和链接的。 而libc并不是Linux上默认的分配器，默认的是 jemalloc, 因为 jemalloc 被证明比libc有更少的碎片问题（fragmentation problems）。 但是如果你没有jemalloc 而只有libc 当然 make 出错。 所以有两种解决办法： 方法一（不推荐） make MALLOC=libc 方法二 cd deps/ make hiredis jemalloc linenoise lua geohash-int 原因参见： 浅谈redis采用不同内存分配器tcmalloc和jemalloc 对于tcmalloc，jemalloc和libc对应的三个内存分配器。其性能和碎片率如何呢？下面是一个简单测试结果，使用Redis自带的redis-benchmark写入等量数据进行测试，数据摘自采用不同分配器时Redis info信息。我们可以看到，采用tcmalloc时碎片率是最低的，为1.01，jemalloc为1.02，而libc的分配器碎片率为1.31， 编译安装 make $$ make install 验证 redis-server -v Redis server v=5.0.4 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=b139020f90f1d493 whereis redis-server redis-server: /usr/local/bin/redis-server 至此，Redis安装完成。 配置通过配置文件，设置Redis服务开机自启动。 设置自启动配置文件 切换目录 cd utils/ 复制脚本文件 cp redis_init_script /etc/init.d/redisd 将redis_init_script文件重新命名为redisd，作为系统启动服务名（以d结尾表示是自启动服务，约定俗成）。 修改配置 vi /etc/init.d/redisd 修改redisd文件，注意要在文件头部加上两句注释来设定该服务的运行级别 #!/bin/sh # chkconfig: 2345 90 10 设置Redis控制脚本的配置文件 切换目录 cd - cd .. 在redis安装目录下，找到redis.conf文件 ls 如下 00-RELEASENOTES INSTALL runtest tests BUGS Makefile runtest-cluster utils CONTRIBUTING MANIFESTO runtest-sentinel COPYING README.md sentinel.conf deps redis.conf src 复制配置文件并重命名 cp redis.conf /etc/redis/6379.conf 编辑Redis配置文件 设置daemonize为yes，使服务可以后台运行： # nu:136 daemonize yes 设置log文件路径： # nu:171 logfile /var/log/redis/redis-server.log 设置持久化文件存放路径： # nu:263 dir /var/lib/redis 保存退出，并创建相应的目录结构： mkdir /var/log/redis touch /var/log/redis/redis-server.log mkdir /var/lib/redis 设置开机自启 Ubuntu # 赋权 chmod +x /etc/init.d/redisd # 更新系统启动项 update-rc.d redisd defaults CentOS [root@master init.d]# chmod +x ./redisd [root@master init.d]# chkconfig redisd on 附：常用redis管理命令 启动Redis服务： service redisd start [root@master init.d]# service redisd start Starting Redis server... # 验证 [root@master init.d]# ps aux|grep redis|grep -v grep root 6728 0.1 0.4 55572 9820 ? Ssl 11:03 0:00 /usr/local/bin/redis-server 127.0.0.1:6379 关闭服务： [root@master init.d]# service redisd stop Stopping ... Redis stopped [root@master init.d]# ps aux|grep redis|grep -v grep 重启服务： service redisd restart 在控制台中登录redis客户端： [root@master init.d]# redis-cli # 测试redis连通性 127.0.0.1:6379&gt; ping PONG 127.0.0.1:6379&gt; set hello world OK 127.0.0.1:6379&gt; get hello &quot;world&quot; 安装提供Python支持pip安装pip install redis 源码安装去https://pypi.org/project/redis/下载源码，Ubuntu上使用最新版本redis 3.2.1 解压 tar -xzvf redis-3.2.1.tar.gz 切换目录 cd redis-3.2.1 安装 python setup.py install 验证 root@local:~/temp/redis-3.2.1# python Python 2.7.15rc1 (default, Apr 15 2018, 21:51:34) [GCC 7.3.0] on linux2 Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; import redis &gt;&gt;&gt; import redis &gt;&gt;&gt; &gt;&gt;&gt; r = redis.Redis(host=&#39;localhost&#39;, port=6379, db=0) &gt;&gt;&gt; ret = r.get(&#39;hello&#39;) &gt;&gt;&gt; print ret world 小插曲 关于redis-py的Python低版本支持 在CentOS上安装redis-3.2.1的时候由于python版本较低（2.6.6）出现以下问题 [root@master redis-3.2.1]# python setup.py install Traceback (most recent call last): File &quot;setup.py&quot;, line 4, in &lt;module&gt; from setuptools import setup ImportError: No module named setuptools 安装setuptools-0.6c9之后执行python setup.py install报错： Traceback (most recent call last): File &quot;setup.py&quot;, line 7, in &lt;module&gt; from redis import __version__ File &quot;/root/temp/pyredis-3.2.1/redis/__init__.py&quot;, line 1, in &lt;module&gt; from redis.client import Redis, StrictRedis File &quot;/root/temp/pyredis-3.2.1/redis/client.py&quot;, line 3046 return {decode(encode(k)): v for k, v in iteritems(data)} ^ SyntaxError: invalid syntax 去官网查看，发现最新版版本支持为： Meta …… Tags: Redis, key-value store Requires: Python &gt;=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.* 以及 Python Version Supportredis-py 3.0 now supports Python 2.7 and Python 3.4+. Python 2.6 and 3.3 support has been dropped. 最后安装较低版本（redis-2.10.6）成功，步骤同上，不再赘述。 读者可以从 这里 获取历史版本：https://pypi.org/project/redis/#history 参考链接 Redis Quick Start Ubuntu安装Redis并设置为开机自启动服务 Python操作Redis数据库]]></content>
      <tags>
        <tag>Redis</tag>
        <tag>NoSQL</tag>
        <tag>数据库</tag>
        <tag>HOWTO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何获取 Ztree 的所有叶子节点？]]></title>
    <url>%2Fblog%2F2019-01-30%2Fhow-to-get-leaf-nodes-of-Ztree%2F</url>
    <content type="text"><![CDATA[使用Ztree时，treeNode.children只能获取到子节点，该如何拿到节点的叶子节点呢？ 创建初始化设置var setting = { data: { simpleData: { enable: true } }, callback: { onCheck:onCheck, } }; 创建点击响应事件function onCheck(event, treeId, treeNode, clickFlag) { var treeObj = $(ELT).fn.zTree.getZTreeObj(&quot;datarecdirs&quot;); var str = &quot;&quot;; str = getAllChildNodes(treeNode,str); // // 加上被选择节点自身 // str = str + &#39;,&#39; + treeNode.id; // 去掉最前面的逗号 var ids = str.substring(1, str.length); // 得到所有节点ID 的数组 var idsArray = ids.split(&#39;,&#39;); // 过滤掉序列中的空元素 [1,2,&#39;3&#39;,&quot;&quot;, &#39;&#39;] &gt;&gt;&gt; [1,2,&#39;3&#39;] (javascript 1.6 and above) var filterArr = idsArray.filter(function(n){return n}); // 得到节点总数量 var leafNodesLen = filterArr.length; if(filterArr){ var nodeChecked = treeNode.checked; if(nodeChecked){ for (var i=0; i &lt; leafNodesLen; i++) { var idVal = filterArr[i]; var node = treeObj.getNodeByParam(&quot;id&quot;, idVal, null); treeObj.setChkDisabled(node,true,false,true); } }else{ for (var j=0; j &lt; leafNodesLen; j++) { idVal = filterArr[j]; // 按照id获取节点，see:https://www.oschina.net/question/222309_131001 node = treeObj.getNodeByParam(&quot;id&quot;, idVal, null); // 注意：此处不可使用getNodeByTId()方法 treeObj.setChkDisabled(node,false,false,true); //取消禁用时，影响到子节点 } var nodes = treeObj.getCheckedNodes(); console.log(nodes); if (nodes.length&gt;0) { for(var c=0;c&lt;nodes.length;c++){ treeObj.checkNode(nodes[c],false,true); //注意，此处不可使用cancelSelectedNode() } } } } } // 递归，获取所有子节点 function getAllChildNodes(treeNode,result){ // 获取节点的所有叶子节点 if (treeNode.isParent) { var childrenNodes = treeNode.children; if (childrenNodes) { for (var i = 0; i &lt; childrenNodes.length; i++) { result += &#39;,&#39; + childrenNodes[i].id; result = getAllChildNodes(childrenNodes[i], result); } } } return result; } 注意 zTree里严格区分了选中和勾选这两个概念，选中是指节点被选择背景颜色有变化，因此cancelSelectedNode()只是把你选择的节点，变成不选择状态，也就是节点的背景色发生变化。而勾选是指节点的勾选框被选中，你要将节点的勾选状态由勾选变为不勾选，就不能使用cancelSelectedNode()方法，只能使用checknode()方法！ 参考来源 zTree 插件 - 获取当前选择节点下的全部子节点 为什么cancelSelectedNode()取消不了节点的选中状态？]]></content>
      <categories>
        <category>工作日常</category>
      </categories>
      <tags>
        <tag>zTree</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次 MySQL 错误 —— mysqld-dead-but-subsys-locked]]></title>
    <url>%2Fblog%2F2019-01-25%2Fmysqld-dead-but-subsys-locked%2F</url>
    <content type="text"><![CDATA[记一次MySQL服务出错排查过程。 今天登录管理系统的时候输入账户信息没有反应，后台查看系统日志发现报错信息： # in tailf /var/log/ODSP.log # out(部分有用信息) 2019-01-25 11:30:07 database [line:263]: Can&#39;t connect to local MySQL server through socket &#39;/var/lib/mysql/mysql.sock&#39; (2) 查看MySQL服务状态# in /etc/init.d/mysqld status # out mysqld dead but subsys locked 查看MySQL的log信息# in tailf /var/log/mysqld.log # out（截取部分有用信息） 700101 00:28:38 mysqld_safe mysqld from pid file /var/run/mysqld/mysqld.pid ended 700101 00:28:42 mysqld_safe Starting mysqld daemon with databases from /secbox/var/db 700101 0:28:42 [ERROR] This MySQL server doesn&#39;t support dates later then 2038 700101 0:28:42 [ERROR] Aborting 查看系统时间[root@master digitools]# date Wed Jan 1 00:31:52 CST 2070 重新设置系统时间[root@master digitools]# date -s &quot;20190125 11:28:50&quot; Fri Jan 25 11:28:50 CST 2019 重新启动MySQL服务[root@master digitools]# /etc/init.d/mysqld status mysqld dead but subsys locked [root@master digitools]# /etc/init.d/mysqld stop Stopping mysqld: [ OK ] [root@master digitools]# /etc/init.d/mysqld start Starting mysqld: [ OK ] # 上面两步命令也可以直接合并为执行 `/etc/init.d/mysqld restart` [root@master digitools]# /etc/init.d/mysqld status mysqld (pid 19402) is running... 日志恢复正常190125 11:30:10 InnoDB: Initializing buffer pool, size = 8.0M 190125 11:30:10 InnoDB: Completed initialization of buffer pool 190125 11:30:10 InnoDB: Started; log sequence number 0 398010 190125 11:30:10 [Note] Event Scheduler: Loaded 0 events 190125 11:30:10 [Note] /usr/libexec/mysqld: ready for connections. Version: &#39;5.1.71&#39; socket: &#39;/var/lib/mysql/mysql.sock&#39; port: 3306 Source distribution 至此，数据库异常问题修复，前台登录系统恢复正常。 参考阅读 Year 2038 problem]]></content>
      <categories>
        <category>工作日常</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重在参与的2018]]></title>
    <url>%2Fblog%2F2019-01-22%2FAnnual-record-of-2018%2F</url>
    <content type="text"><![CDATA[岁月不居，时光如流。今天心血来潮换了个 Hexo 的主题——FreeMind。原本的 Material 主题在将网站背景图片自定义为 Bing 随机图片之后会打开很慢，按照「超过 3 秒都是病」的原则，遂换上了现在的主题。本该早点对 2018 年做个年终总结的（虽然也没什么人看），可是最近拖延症发作加上一直加班，所以就很久没更新博客和公众号了。（注意：这是我为自己找的一个骗人的借口。） 首先对 2018 年立的 Flag 做个简单回顾： 找个女朋友； 今年认识了2、3个女生，不过令人遗憾的是到头来还是无功而返。（我们跟随着可怜的小家伙的脚步，到头来发现这个笨蛋还是没能送出祖传的 DNA !）还有一个令人绝望的消息是：由于年龄的增长，逐渐对现实有了清晰一点的认识，意识到大多数人根本没有收获爱情的可能，大多数到头来只是对生活做出妥协找了一个伙伴以降低生活中的不可控风险。可能比起爱情来，找一个在事业或者生活上可以为你提供帮助的人，甚至只是性格上合得来的同伴相对现实一些。 克服困难，通过节食加锻炼将体重控制在可接受的范围之内； 今年的体重总体上来说形成了一条「微笑曲线」。六月份到十月份之间通过跑步和不规律性的节食减掉了将近 20 斤。然而由于天气转冷后人变懒了，跑步中止，运动放弃，现在体重又恢复到 140 斤左右。所以只能说万幸没有增重，但是减肥的结果依然不是很理想。 工作今年总体上来说没有什么大的收获，甚至可以说有点乏味。每天都忙着解决公司代码中的 BUG ,技术上也没有很大的提高，在这种重复中想要提高自己真的很慢，同时没有动力和意志去学习成长提高自己。偶尔只是在心血来潮的那么一下子做个「马来人」收集一些看起来有用的资料，可是到头来真的沉下心去看的机会依然很少。 生活两点一线的废柴生活没有多少波澜，也没有什么值得浪费笔墨的点。噩耗是并不年迈的舅舅却因为意外去世。实际上三舅是我比较钦佩的一个亲人，在上个世纪大家受教育程度普遍不高的大背景下通过个人辛勤劳动攒下百万家产，同时对亲人也很热心。我生性孤冷，一向不擅于表达自己的感情。原本想着在朋友圈纪念一下舅舅的去世，又担心被别人认为是哗众取宠的傻×，所以暂且在这里写下一段文字聊表对舅舅去世的惋惜吧。 呜呼，天降灾否，小甥伤悲，痛何如哉！ 您性也孝，外婆久病，不嫌不弃，以克终养；您性又贤，姊妹有难，亲力亲为，急其所难。 余忆幼时，不辨叔舅，呼汝大大，惹人捧腹；童龀之年，舅父严厉，甩鞭山响，吓我趋走。 再忆高中，条件艰苦，披星戴月，载我回家；呜呼，言有穷而情不可终。呜呼哀哉！伏惟尚飨！ 一点困惑 Q: 只写代码是否过好这一生？随着年龄增长如何不被新人替代？ 程序员工作是一个不断学习的职业，在一个公司呆久了可能对公司的代码特别熟悉。但是对熟悉的东西越熟悉，对陌生的东西可能也会逐渐变得更加陌生。在这样的情况下，如果避免「后来者居上」的尴尬？ Q: 如何提高自己的亲和力，变成一个让别人感觉舒服的陌生人？ 同样是一个和你无怨无仇的同事，为什么有的人你和 Ta 很聊得来，有的人只是表面应付，其实内心很抵触和 Ta 沟通？排除颜值上面的外在因素，还有什么在影响着人与人之间的和谐相处呢？ 展望2019 年可能会考虑换一个工作环境。一方面希望技术能够有更好的锤炼，感觉自己还需要在深广度上学习一个，而目前的工作更多的只是一些很基础的操作，很多高级用法根本没有应用场景，因此缺少学习的动力；另一方面，在一个平常的地方待久了，人也没有了危机感和进取心。 吾常身不离鞍，髀肉皆消。今不复骑，髀里肉生。日月若驰，老将至矣，而功业不建，是以悲耳。 还有，计划在找好工作之后报考驾照，我原本以为无人驾驶技术的普及到后来就没有必要学习驾照。但是现在看来当初对的预测有点乐观。或许的可期的未来，城市之中的热点线路上自动化驾驶技术可以实现普及，但是在更多的个性化定制方面可能依然需要假以时日。一如人们吐槽的那样，目前的人工智能暂时还只能被叫做「人工智障」。 老生常谈的一件事：既然没有能力做一个单身贵族，那么还是要尽量努力解决个人问题，不要让父母过分担心。但是这个问题我更多的只能尽人事而知天命，有合适的姑娘的话加倍努力，没合适的我也只能有心杀贼，无力回天啦！ 心有大愿，不计风雨，风雨之中，愿你安好，阳光之下，愿你灿烂。 胸有鸿鹄志，奈何燕雀身。今天很难,明天更难。真是「长恨此身非我有」，不知「何时忘却营营」。正所谓万物之中,希望至美。 加油吧！ 鸿鹄之志千万里，你勃然而起。嘿我能，嘿我能，老子可以！你引颈向天歌一曲。天将降大任于你，磨练你的筋骨皮。玉不琢不成器，出水才见两腿泥住大房子开大车嗅大蜜，谁家的姑娘都能明媒正娶。让那些狗眼看人低的东西，再也不敢瞧不起你。 你爸爸不是贪官污吏，母亲是良家妇女。你也没有可以让你少奋斗十年的上流社会关系。幻想的假象多么美丽，你很傻很天真。这真枪实弹的成人游戏，很黄很暴力。 路漫漫其修远兮，十万八千里。时运不济你的磨难兮，九九八十一。你用鸡生蛋用蛋生鸡，真他妈不容易。他突然一场暴风雨，鸡飞蛋打了。 昨日的朋友今非昔比，你再也没有兴趣谈起。昔日的恋人随青春而去，童话般的回忆。 夕阳西下湖水边的倒影里，你看清楚了自己。妻子在不远处呼唤着你的名字，儿子跑过来说他会多么了不起。 鸿鹄志你的鸿鹄志，像一首年少轻狂的诗。那曾经自命不凡的日子，在多年以后一笑了之。鸿鹄志你的鸿鹄之志，像一首年少轻狂的诗。 那曾经自命不凡的日子，在上下班的人流中慢慢消失。在你的酒杯中慢慢消失，在你的床单上慢慢消失，在你的工资里慢慢消失，在现实的旋涡中慢慢消失。]]></content>
      <categories>
        <category>个人日记</category>
      </categories>
      <tags>
        <tag>Diary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip小老弟，你怎么肥四？]]></title>
    <url>%2Fblog%2F2018-09-21%2Fget-some-trouble-with-pip%2F</url>
    <content type="text"><![CDATA[今天用pip的时候突然不能正常使用，在这里简单记录一下。 提示pip版本不对错误提示You are using pip version 9.0.3, however version 18.0.1 is available. You should consider upgrading via the &#39;python -m pip install --upgrade pip&#39; command. 处理过程去官网下载最新版的包，直接解压安装即可； 参考来源Python2.7 自带的pip9.0 升级到pip18.0 明确已经安装pip，但是系统提示找不到pip错误提示-bash: /home/imoyao/.local/bin/pip: No such file or directory 解决方案1.which pip /usr/local/bin/pip 2.pip -su: /usr/bin/pip: No such file or directory 3.type pip pip is hashed (/usr/bin/pip) So pip is definintely in /usr/local/bin/pip but it is been cached as in /usr/bin/pip, thanks to the Stackoverflow question, the solution is very simple: 4.hash -r When the cache is clear, pip is working again. 参考来源/usr/bin/pip: No such file or directory 安装或升级pip时提示SSLError错误提示Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by &#39;SSLError(SSLError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:833)&#39;),)&#39;: /simple/pip/ Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by &#39;SSLError(SSLError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:833)&#39;),)&#39;: /simple/pip/ Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by &#39;SSLError(SSLError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:833)&#39;),)&#39;: /simple/pip/ Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by &#39;SSLError(SSLError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:833)&#39;),)&#39;: /simple/pip/ Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by &#39;SSLError(SSLError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:833)&#39;),)&#39;: /simple/pip/ Could not fetch URL https://pypi.python.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host=&#39;pypi.python.org&#39;, port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:833)&#39;),)) - skipping #其实本人遇到的错误是 (Caused by SSLError(SSLError(1, u&#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:726)&#39;),)) 解决方案 临时方案 安装时添加参数： --trusted-host pypi.python.org 此方式表示信任该域名，但是每一次安装包的时候都需要该操作，比较麻烦； 永久方案 修改pip.conf 配置文件，该文件在Linux系统中的可能位置： /etc/pip.conf ~/.pip/pip.conf ~/.config/pip/pip.conf 如果都没有的话，可以手动创建之后添加以下内容： [global] index-url = http://mirrors.aliyun.com/pypi/simple/ # 本机使用阿里源代理 [install] trusted-host=mirrors.aliyun.com # global字段还看到其他写法： [global] trusted-host = pypi.python.org pypi.org files.pythonhosted.org 参考来源pip issue installing almost any librarylinux 设置pip 镜像 Pip Warning：–trusted-host 问题解决方案 安装MySQL-python时提示：错误提示EnvironmentError: mysql_config not found 解决方案 CentOS yum install libffi-devel pip install mysql-connector-python Ubuntu sudo apt install default-libmysqlclient-dev 参考来源pip install mysql-python fails with EnvironmentError: mysql_config not found]]></content>
      <tags>
        <tag>Python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DRBD状态指标记录]]></title>
    <url>%2Fblog%2F2018-08-29%2Fstate-of-drbd%2F</url>
    <content type="text"><![CDATA[在管理DRBD的时候，需要关注drbd相关的各种状态指标，本文主要记录相关的指令及显示含义。 DRBD状态概览drbd-overview drbd status cat /proc/drbd # 9.0废止在drbd9中，更多的是使用drbdadm或drbdsetup来获取节点的状态信息。 以上命令略有不同，可自行对照 [root@Storage drbd]# pwd /usr/lib/drbd [root@Storage drbd]# ./drbd status # 输出示例 drbd driver loaded OK; device status: version: 8.4.3 (api:1/proto:86-101) GIT-hash: 89a2942***221f964d3ee515 build by root@third, 2017-07-20 10:58:42 m:res cs ro ds p mounted fstype 0:drbd0 Connected Primary/Secondary UpToDate/UpToDate C 1:drbd1^^0 StandAlone Primary/Unknown UpToDate/DUnknown r----s …… 6:drbd6 Connected Primary/Secondary UpToDate/UpToDate C /xxx ext4 习惯上，我们使用cat /proc/drbd获取drbd状态信息。 [root@Storage ~]# cat /proc/drbd version: 8.4.3 (api:1/proto:86-101) srcversion: 9D811F04CD6DC2C9A9A608F 3: cs:Connected ro:Secondary/Secondary ds:UpToDate/UpToDate C r----- ns:0 nr:0 dw:0 dr:0 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0 301: cs:Connected ro:Secondary/Secondary ds:UpToDate/UpToDate C r----- ns:0 nr:0 dw:0 dr:0 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0 缩写解释 res：资源名称 cs：connect state,资源连接状态 ro：role，表示节点角色信息第一次启动drbd时，两个drbd节点默认都处于Secondary状态，Primary/Secondary（代表这个是主节点）Secondary/Primary（代表这个是副节点） ds：disk state,磁盘状态信息Inconsistent/Inconsisten，即为“不一致/不一致”状态，表示两个节点的磁盘数据处于不一致状态。UpToDate/Inconsistent（正在同步，数据还没有一致）UpToDate/UpToDate （同步完成，数据一致） C drbd的复制协议，即A、B、C协议。 r—–是IO标记，反映的是该资源的IO状态信息。共有6种IO状态标记符号。 连接状态节点间通过TCP连接进行通信，在建立连接、断开连接、特殊情况下有很多种连接状态。 DRBD连接建立完成，表示元数据区、数据区等一切都已准备好，可以进行任何数据同步的操作。 [root@master ~]# drbdadm cstate drbd20 Connected 一个资源可能有以下连接状态中的一种 Unconfigured：设备在等待配置 WFConnection：当前节点正在等待对端节点出现。例如对方节点drbdadm down后，本节点将处于本状态。 StandAlone：无连接。出现这种状态可能是因为：未连接过、使用drbdadm disconnect断开连接、节点由于身份验证的原因未成功加入drbd集群使得连接被删除、脑裂后断开连接。 Disconnecting：断开连接的一个临时过渡状态。它很快就会切入下一状态就是StandAlone。 Unconnected：尝试再次发起TCP连接时的一个临时连接状态(是连接超时后再次发送连接请求产生的状态)，它的下一个状态可能是WFConnection，也可能是WFReportParams。 Timeout：和对端通信超时时的临时状态。下一个状态就是Unconnection。 BrokenPipe：和对端连接丢失时的临时状态。下一个状态是Unconnection。 NetworkFailure：和对端连接丢失时的临时状态。下一个状态是Unconnection。(没错，和上面的一样) ProtocolError：和对端连接丢失时的临时状态。下一个状态是Unconnection。(没错，还是和上面的一样) TearDown：对端关闭TCP连接时的临时状态。下一个状态是Unconnection。 Connected：DRBD连接已经建立完成，数据镜像已经激活成功。这个状态是drbd正常运行时的状态。 WFReportParams：TCP连接已经建立完成，该节点正在等待对端的第一个数据包。 StartingSyncS：全盘数据同步中。只有在初始化时才应该全盘同步。下一个状态是：SyncSource或PauseSyncS。 StartingSyncT：全盘数据同步中。只有在初始化时才应该全盘同步。下一个状态是：WFSyncUUID。 WFBitMapS：部分数据正在同步。下一个状态是：SyncSource或PauseSyncS。 WFBitMapT：部分数据正在同步。下一个状态是：WFSyncUUID。 WFSyncUUID：同步马上就要开始了。下一个状态：SyncTarget或PauseSyncT。 SyncSource：正在同步，且本节点是数据同步的源端。 SyncTartget：正在同步，且本节点是数据同步的目标端。 PauseSyncS：本节点是同步的源端节点，但同步过程当前被暂停。出现这种状态的原因可能是当前同步进程依赖于另一个同步进程完成，或者使用drbdadm pause-sync手动中断了同步操作。 PauseSyncT：本节点是同步的目标端，但同步过程当前被暂停。出现这种状态的原因可能是当前同步进程依赖于另一个同步进程完成，或者使用drbdadm pause-sync手动中断了同步操作。 VerifyS：正在进行在线设备验证，且本节点将成为验证的源端。 VerifyT：正在进行在线设备验证，且本节点将成为验证的目标端。 在drbd9中，WFConnection状态改为connecting状态。删除了WFReportParams状态。添加了以下几个同步相关的状态： Off：该卷组还未同步，因为连接未建立。 Established：所有对该卷组的写操作已经在线完成同步。这是drbd正常运行时的状态。 Ahead：数据同步操作被挂起，因为网络套接字中达到了一定的堵塞程度，无法应付更多的负载。该状态需要配置on-congestion选项来启用。 Behind：对端将数据同步操作挂起，因为网络套接字中达到了一定的堵塞程度，无法应付更多的负载。该状态需要在对端节点上配置on-congestion选项来启用。 角色状态资源的角色状态既可以从/proc/drbd文件中获取，也可以使用下面的命令来获取。 [root@drbd1 ~]# drbdadm role data1 Primary/Unknown 在角色状态信息中，本地节点总是标记在第一位，远程节点标记在结尾。 可能的节点角色状态有： Primary：资源的primary角色，该角色状态下的drbd设备可以进行挂载、读、写等。在没有启用多主复制模型(dual-primary mode)，只能有一个primary节点。 Secondary：资源的secondary角色。该角色状态下的drbd设备会接收来自primary端的数据更新(除非和对端不是primary)。且该角色的drbd设备不可挂载、不可读、不可写。 Unknown：资源的角色未知。本地节点的角色状态绝对不可能会是这种状态。只有对端节点断开连接时对端节点才处于Unknown状态。 硬盘状态[root@master ~]# drbdadm dstate drbd20 UpToDate/UpToDate 在磁盘状态信息中，本地节点的磁盘状态总是标记在第一位，远程节点标记在结尾。本地和对等节点的硬盘有可能为下列状态之一： Diskless 无盘：本地没有块设备分配给DRBD使用，这意味着资源可能从没有和它的底层块设备进行关联绑定(attach)，也可能是手动detach解除了关联，还可能是出现了底层I/O错误时自动分离（detach）。 Attaching：读取无数据时候的瞬间状态 Failed：失败，本地块设备报告I/O错误的下一个状态，其下一个状态为Diskless无盘 Negotiating：在已经连接的DRBD设置进行Attach读取无数据前的瞬间状态 Inconsistent：数据不一致，在两个节点上（初始的完全同步前）这种状态出现后立即创建一个新的资源。此外，在同步期间（同步目标端）正接收同步数据时，也会进入不一致状态。 Outdated：数据资源是一致的，但是已经过时。(例如，已经同步后secondary下线了，之后又上线了，在还没开始重新同步的时候就是Outdated状态) DUnknown：当对等节点网络连接不可用时出现这种状态 Consistent：连接断开时的数据处于一致性状态，当连接建立后，将决定数据是UpToDate还是Outdated状态 UpToDate：一致的、最新的数据状态，这个状态为正常状态 IO状态标记IO状态标记表示的是当前资源的IO操作状态。共有6种状态： IO挂起：r或s都可能表示IO挂起，一般是r。r=running，s=suspended。 串行重新同步：资源正在等待进行重新同步，但被resync-after选项延迟了同步进度。该状态标记为”a”，通常该状态栏应该处于”-“。 对端初始化同步挂起：资源正在等待进行重新同步，但对端节点因为某些原因而IO挂起。该状态标记为”p”，通常该状态栏应该处于”-“。 本地初始化同步挂起：资源正在等待进行重新同步，但本节点因为某些原因而IO挂起。该状态标记为”u”，通常该状态栏应该处于”-“。 本地IO阻塞：通常该状态栏应该处于”-“。可能有以下几种标记： d：因为DRBD内部原因导致的IO阻塞。 b：后端设备正处于IO阻塞。 n：网络套接字阻塞。 a：网络套接字和后端块设备同时处于阻塞状态。 Activity Log更新挂起：当al更新被挂起时，处于该状态，标记为”s”，通常该状态栏应该处于”-“。(如果不知道什么是Active Log，请无视本标记) 性能指标主要是一些计数器和计量器的值。 drbd84中使用缩写符号来标记性能指标，而drbd9中使用全称来表示。例如drbd84中的ns和drbd9中的send是同一个意思。 ns/send (network send)：通过网络连接发送给对端的数据量，单位为Kb。 nr/receive (network receive)：通过网络连接接收到对端发送来的数据量，单位为Kb。 dw/written (disk write)：该卷(volume)写入本地磁盘的数据量，单位为Kb。 dr/read (disk read)：该卷(volume)从本地磁盘读取的数据量，单位为Kb。 al/al-writes (activity log)：元数据区中al更新的次数。 bm/bm-writes (bit map)：元数据区中bitmap更新的次数。 lo/lower-pending (local count)：DRBD发起的打开本地IO子系统的请求次数。 pe/pending (pending)：本地发送给对端但却没有回复的次数。 ua/unacked (unacknowledged)：接收到对端发送的请求但却没有给予回复的请求数量。 ap/upper-pending (application pending)：转发给DRBD的IO块的请求，但DRBD还没给予回复的请求数量。 ep (epochs):epoch对象的数量。通常为1。drbd9中没有该指标。 wo/write-ordering (write order):当前正在使用的write order方法：b(barrier), f(flush), d(drain)或n(none)。 oos/out-of-sync (out of sync):当前不同步的数据量，单位为Kb。 上面所有”未给予回复”的指标数量都表示动作还未完成，需要回复后才表示操作完成。这些未回复数值不能太大。 此外，drbd9中添加了以下几个指标： resync-suspended：重新同步操作当前是否被挂起。可能的值为no/user/peer/dependency。 blocked：本地IO的拥挤情况。 no：本地IO不拥挤。 upper：DRBD层之上的IO被阻塞。例如到文件系统上的IO阻塞。可能有以下几种原因： 管理员使用drbdadm suspend-io命令挂起了I/O操作。 短暂的IO阻塞，例如attach/detach导致的。 删除了缓冲区。 bitmap的IO等待。 lower：底层设备处于拥挤状态。 参考链接 drbd(三)：drbd的状态说明 - 骏马金龙 - 博客园]]></content>
      <categories>
        <category>教程记录</category>
      </categories>
      <tags>
        <tag>DRBD</tag>
        <tag>Linux</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 DRBD 使用外部元数据]]></title>
    <url>%2Fblog%2F2018-08-28%2Fdrbd-with-external-disk%2F</url>
    <content type="text"><![CDATA[裂脑一旦发生，需要及时排查问题所在，最大限度保护数据完整性。mathjax meta data存放位置优缺点比较internal meta-datameta-data和数据存放在同一个底层设备之上，它通过在设备末端预留一个区域以存储元数据做到这一点。 优点： 一旦meta-data创建之后，就和实际数据绑在了一起，在维护上会更简单方便，不用担心meta-data会因为某些操作而丢失。另外在硬盘损坏丢失数据的同时，meta-data也跟着一起丢失，当更换硬盘之后，只需要执行重建meta-data的命令即可，丢失的数据会很容易的从其他节点同步过来。 缺点： 如果底层设备是单一的磁盘，没有做raid，也不是lvm等，那么可能会对写入吞吐量产生负面影响。因为每一次写io都需要更新meta-data里面的信息，那么每次写io都会有两次，而且肯定会有磁头的较大寻道移动，因为meta-data都是记录在设备的最末端的，这样就会造成写io的性能降低。 external meta datameta-data存放在独立的，与存放数据的设备分开的设备之上。 优点： 与internal meta-data的缺点完全相对。对于某些写操作, 使用外部元数据会稍微改进延迟行为。 缺点： 由于meta-data存放在与数据设备分开的地方，就意味着如果磁盘故障且仅破坏生产数据 (而不是 DRBD 元数据), 则可以通过手动干预, 以使发起从幸存的节点到后续更换的磁盘上的完整数据同步。也就是管理维护会稍微麻烦一点，很小的一点点。 注意： 如果我们希望在已经存在数据的设备上面建立drbd的资源，并且不希望丢失该设备上面的数据，又没办法增大底层设备的容量，而且上层文件系统不支持收缩，我们就只能将meta data创建成external方式。 估算元数据大小注意：如果公式渲染出错，可以去这里预览 你可以使用以下公式计算 DRBD 元数据的精确空间要求: $$M{S}= \lceil\frac{C{s}}{2^{18}} \rceil \ast 8 \ast N + 72$$ Cs 是存储设备扇区大小。N是对端的数量，一般情况下drbd实现的是双节点，因此N=1，可以不用考虑。 您可以通过发出 blockdev –getsz 来检索设备大小。 [root@Storage ~]# blockdev --getsz /dev/StorPool1/SANLun2 2097152 结果中的Ms的大小也是用扇区表示的,要转换为 MB, 请除以 2048。(对于512字节的扇区大小, 这是除 s390 之外的所有 Linux 平台上的默认值)。 In [23]: (math.ceil(2097152/2**18)*8+72)/float(2048) Out[23]: 0.06640625 在实践中, 你可以使用一个合理的好的近似, 下面给出。请注意, 在此公式中, 单位为兆字节(megabytes), 而非扇区: $$M{MB} \lt \frac{C{MB}}{32768} \ast N + 1$$ # 获取块设备大小 [root@Storage ~]# lsblk /dev/StorPool1/SANLun2 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT StorPool1-SANLun2 253:3 0 1G 0 lvm # 预估元数据设备大小 In [30]: 1024/float(32768)+1 Out[30]: 1.03125 此处插播一个小的知识点,来源参考这里（解释）和这里（区别）。 名字 缩写 次方 名字 缩写 次方 kilobyte KB 10^3 kibibyte KiB 2^10 megabyte MB 10^6 mebibyte MiB 2^20 gigabyte GB 10^9 gibibyte GiB 2^30 terabyte TB 10^12 tebibyte TiB 2^40 petabyte PB 10^15 pebibyte PiB 2^50 exabyte EB 10^18 exbibyte EiB 2^60 zettabyte ZB 10^21 zebibyte ZiB 2^70 yottabyte YB 10^24 yobibyte YiB 2^80 重置资源的大小在线增加需要满足两个条件： 支持设备必须是逻辑卷 当前的资源必须处于connected的连接状态。 在两个节点给设备增加大小后，再确认只有一个节点处于primary状态。然后输入： drbdadm resize &lt;resource&gt; 此命令会触发新扇区的同步，完成主节点到备用节点间的同步。 如果你添加的空间是干净没有数据的，你可以使用--assume-clean选项： drbdadm -- --assume-clean resize &lt;resource&gt; 来跳过额外的空间同步。 离线增加（此为高级功能，请自审之后使用。） 资源被配置为external meta data时 当DRBD在处于非活动情况下，在两个节点的支持设备被扩展时，且DRBD资源使用的是external meta data，那么新的大小会自动被识别，不需要管理员干预。DRBD设备将在下次两个节点活动并且成功建立网络连接之后，显示增加后的新容量。 资源被配置为internal meta data时 当DRBD资源被配置为使用 internal meta data时，在新大小变为可用之前, 则必须将此元数据移动到已扩容设备的末尾。为此, 请完成以下步骤: down掉DRBD资源: drbdadm down &lt;resource&gt; 在收缩之前将元数据保存在文本文件中 drbdadm dump-md &lt;resource&gt; &gt; /tmp/metadata 注意： 以上步骤必须在两个节点上分别运行。不能在一个节点上保存了元数据然后在拷贝到另外一个节点上。否则就无法正常工作。 在两个节点上给支持的块设备增加容量 分别在两个节点上调整/tmp/metadata 文件中la-size-sect的大小信息。注：这里la-size-sect指定的是扇区数量 重新初始化元数据区域 drbdadm create-md &lt;resource&gt; 分别在两个节点上重新导入修正的元数据 ## 此处使用bash脚本，需要确认可用性 # drbdmeta_cmd=$(drbdadm -d dump-md &lt;resource&gt;) # ${drbdmeta_cmd/dump-md/restore-md} /tmp/metadata Valid meta-data in place, overwrite? [need to type &#39;yes&#39; to confirm] yes Successfully restored meta data 重新启用DRBD资源 drbdadm up &lt;resource&gt; 在一个节点上，设置DRBD为primary drbdadm primary &lt;resource&gt; 至此，已完成DRBD设备大小的扩容。 在线缩小容量注：在线缩小容量，仅支持external metadata 在缩小DRBD设备时必须首先缩小DRBD的上层块设备。例如文件系统。由于DRBD无法获知文件系统到底使用了多少空间，所以在缩小文件系统时需要格外小心防止数据丢失！文件系统是否可以被缩小取决于所使用的文件系统。大多数文件系统不支持在线缩减。XFS也不支持在线缩减。 因此，在缩小文件系统后，可以使用以下命令在线缩小DRBD设备容量。 drbdadm resize --size=&lt;new-size&gt; &lt;resource&gt; 离线收缩容量（此为高级功能，请自审之后使用。） 如果在 DRBD 处于非活动状态时收缩后备块设备, DRBD 将拒绝在下次尝试attach期间attach到此块设备, 因为它现在太小 (external meta-data), 或者它将无法找到其元数据 (internal meta-data)。要变通解决这些问题, 请使用此过程 (如果不能使用上面的在线收缩): 在DRBD还处于配置运行状态时，在一个节点上缩小文件系统 down掉DRBD资源 drbdadm down &lt;resource&gt; 在缩小前保存元数据到一个文件中： drbdadm dump-md &lt;resource&gt; &gt; /tmp/metadata 注意： 以上步骤必须在两个节点上分别运行。不能在一个节点上保存了元数据然后在拷贝到另外一个节点上。否则就无法正常工作。 在两个节点上给支持的块设备缩小容量 分别在两个节点上调整/tmp/metadata 文件中la-size-sect的大小信息。注：这里la-size-sect指定的是扇区数量 重新初始化元数据区域 drbdadm create-md &lt;resource&gt; 分别在两个节点上重新导入修正的元数据 ## 此处使用bash脚本，需要确认可用性 # drbdmeta_cmd=$(drbdadm -d dump-md &lt;resource&gt;) # ${drbdmeta_cmd/dump-md/restore-md} /tmp/metadata Valid meta-data in place, overwrite? [need to type &#39;yes&#39; to confirm] yes Successfully restored meta data 重新启用DRBD资源 drbdadm up &lt;resource&gt; 其他说明查看元数据# down 掉drbd [root@Storage ~]# drbdadm down drbds2 # 查看元数据出错 [root@Storage ~]# drbdadm dump-md drbds2 Found meta data is &quot;unclean&quot;, please apply-al first Command &#39;drbdmeta 2 v08 /dev/StorPool1/SANLun2 internal dump-md&#39; terminated with exit code 255 # 暂时不明白这句操作的含义，待查 [root@Storage ~]# drbdadm apply-al drbds2 # 查看meata-data [root@Storage ~]# drbdadm dump-md drbds2 # DRBD meta data dump # 2018-08-29 01:48:20 +0800 [1535478500] # Storage&gt; drbdmeta 2 v08 /dev/StorPool1/SANLun2 internal dump-md # version &quot;v08&quot;; # md_size_sect 136 # md_offset 1073737728 # al_offset 1073704960 # bm_offset 1073672192 uuid { 0xDDB03F0DAF07DEDC; 0x0000000000000000; 0xE4689A94FBB0E78B; 0xE4679A94FBB0E78B; flags 0x00000000; } # al-extents 1237; la-size-sect 2097016; bm-byte-per-bit 4096; device-uuid 0x625F486D2CB120D1; la-peer-max-bio-size 1048576; al-stripes 1; al-stripe-size-4k 8; # bm-bytes 32768; bm { # at 0kB 4096 times 0x0000000000000000; } # bits-set 0; 从此命令中可以获知不同标记代数的uuid值，以及metadata的元数据信息，例如md_size_sect=1951744表示元数据所在分区占用了1951744个扇区。注意，该命令不要在drbd设备已启动的情况下执行。 知道这两个命令可以获取一些信息后，现在我们要做的是计算metadata部分的数据大小。这个大小在”修改drbd设备空间大小”时有用。 首先获取元数据所在分区的扇区数。即上面结果中的”md_size_sect”。不过也可以使用块设备工具blockdev来获取。 参考来源 16.1. DRBD meta data 原创 | drbd中metadata的理解 drbd配置简述 drbd(二)：配置和使用 - 骏马金龙 - 博客园]]></content>
      <tags>
        <tag>DRBD</tag>
        <tag>存储</tag>
        <tag>meta-data</tag>
        <tag>元数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DRBD用户手册之命令篇]]></title>
    <url>%2Fblog%2F2018-06-22%2Fcommonds-of-drbd%2F</url>
    <content type="text"><![CDATA[本文基于DRBD-8.4版编写。 drbd.conf-配置文件TODO drbdmeata-元数据TODO drbdTODO drbdadm-管理工具名称drbdadm - DRBD管理工具 概要drbdadm [-d] [-c { file}] [-t {file}] [-s {cmd}] [-m { cmd}] [-S] [-h {host}] [-- { backend-options}] {command} [{all} | { resource[/volume&gt;]...}] 描述Drbdadm是DRBD程序套件的高级工具。 Drbdadm与drbdsetup和drbdmeta的关系可类比于 ifup / ifdown与ifconfig 。 Drbdadm通过调用drbdsetup和（或）drbdmeta程序读取相关配置文件并执行指定的命令。Drbdadm可以运行整个资源或资源中的单个卷。 子命令： attach ， detach ， primary ， secondary， invalidate ， invalidate-remote ， outdate ， resize ， verify ， pause-sync ， resume-sync ， role ， cstate ， dstate ， create-md ， show-gi ， get-gi ， dump-md ， wipe-md可以作用于整个资源和单个卷上。仅限资源级别的命令有：connect, disconnect, up, down, wait-connect 和 dump 。 选项 -d ，– dry-run 仅将drbdsetup的调用打印到stdout，但不会运行这些命令。 -c ，– config-file 文件 指定drbdadm将使用的配置文件。 如果未指定此参数，则drbdadm将查找/etc/drbd-84.conf、/etc/drbd-83.conf、/etc/drbd-08.conf和/etc/drbd.conf 。 -t ，– config-to-test 文件 指定一个额外的drbdadm检查文件。 该选项仅适用于dump和sh-nop命令。 -s ，– drbdsetup 文件 指定drbdsetup程序的完整路径。 如果省略此选项，drbdadm将首先内部查找它，然后在PATH环境变量中查找它。 -m ，– drbdmeta 文件 指定drbdmeta程序的完整路径。 如果省略此选项，drbdadm将首先内部查找它，然后在PATH中查找它。 -S ， –stacked 指定应该在堆叠资源上执行此命令。 -P ， –peer 指定要连接的对等节点。 只有当您正在使用的资源中有两个以上的主机时才需要此选项。 后端配置选项 双连字符（–）后面的所有选项都被视为后端选项。这些选项会传递给后端命令。 即drbdsetup、drbdmeta或drbd-proxy-ctl 。 命令 attach 将本地支持块设备连接到DRBD资源的设备。 detach 从DRBD资源的设备中删除备份存储设备。 connect 建立资源设备的网络配置。 如果对等设备已配置，则两个DRBD设备将连接。 如果资源中有两个以上的主机部分，则需要使用--peer选项来选择要连接的对等端。 disconnect 从资源中删除网络配置。 设备将进入StandAlone状态。 syncer（注：drbdadm --help 未发现该命令） 将重新同步参数加载到设备中。 up 是attach、syncer和 connect的快捷方式。 实际上，可以将drbdadm up拆分为以下几个动作： 将drbd的资源关联到底层设备(metadata和data区)上，使之能通过底层设备存、取数据。该过程调用的是drbdsetup程序。drbdadm attach drbd1 加载drbd资源的同步参数。drbdadm syncer drbd1 连接对端。drbdadm connect drbd1 这些命令在drbdadm中部分已弃用，放在这里只是为了说明up时所执行的几个步骤。 down 是disconnect 和 detach的捷径。 primary 将资源设备转化为主要角色。 您需要在访问设备之前执行此操作，如创建或挂载文件系统。 secondary 将设备转回次要角色。 这是必需的，因为在连接状态的DRBD设备对中，两个节点中只能有一个节点是主端（除非在配置文件中明确设置了allow-two-primaries ）。 invalidate 强制DRBD将本地存储设备上的数据视为不同步（out-of-sync）。 因此，DRBD将复制其对等体中的每个块，以使本地存储设备重新同步。 为避免竞争，你需要建立了的复制链接，或断开连接的次端。 invalidate-remote 该命令类似于invalidate命令，但是是对等端的备份存储被视为无效，因此对端被本地节点的数据重写。 为避免竞争，您需要已建立的复制链接，或断开连接的主端。 resize DRBD重新检查所有大小限制，并相应调整资源的设备大小。 例如，如果您增加了备份存储设备的大小（当然是在两个节点上均进行次操作），那么在您的某个节点上调用此命令后，DRBD将采用新的大小。 由于必须同步新的存储空间，因此只有存在至少一个主节点时，此命令才可用。--size选项可用于联机缩小drbd设备的可用大小。 用户必须负责确保设备上的文件系统不被该操作截断。--assume-peer-have-space允许你调整当前未连接到对等设备的设备。 使用时需要小心，因为如果您不重新调整对等磁盘的大小，则两者的进一步连接尝试将失败。--assume-clean允许您调整现有设备的大小并避免同步新的空间。 将附加空白存储添加到设备时，这样操作非常有用。 例： # drbdadm -- --assume-clean resize r0 选项-al-stripes和--al-stripe-size-kB可用于在线更改 activity log的布局。 在使用内部元数据的情况下，这可能会同时缩小用户可见大小（使用--size ）或增加后备设备上的可用空间。 check-resize 调用drbdmeta达到移动内部元数据的目的。 如果后台设备的大小已调整，而DRBD未运行，则必须将元数据移至设备的末尾，以便接下来的 attach 命令可以成功。 create-md 初始化元数据存储。 这需要在DRBD资源首次上线之前完成。 如果有关于该命令的问题请看drbdmeta get-gi 显示数据生成标识符(GI元祖)的简短文字表示。 show-gi 打印包含说明信息的数据生成标识符的文本表示。 dump-md 以文本形式转储元数据存储的全部内容，包括存储的位图和活动日志。 outdate 设置元数据中的过期标志。 adjust 将设备的配置与你的配置文件同步。 在实际执行此命令之前，应始终检查dry-run模式的输出。 wait-connect 等待设备连接到对等设备。 role 显示设备的当前角色（local/peer）。 例如：Primary/Secondary state 不赞成使用（废止），“角色”的别名，参见上文。 cstate 显示设备的当前连接状态。如：Connected、StandAlone等 dump 解析配置文件并将其转储到stdout。 可用于检查配置文件的语法正确性。 outdate 用于将节点的数据标记为过时。 通常由对等方的fence-peer处理程序使用。 verify 开始在线验证。 在线验证期间，比较两个节点上的数据是否相等。 请参阅/proc/drbd进行在线验证。 如果发现不同步块，则它们不会自动重新同步。因此，请在验证完成后使用disconnect 和connect断开并连接资源。另请参阅drbd.conf联机帮助页上有关数据完整性的注意事项。 pause-sync 通过设置本地暂停标志暂时中止正在进行的重新同步。 如果本地和远程暂停标志均未设置，则同步进行。 可能需要推迟DRBD的重新同步到支持存储的RAID设置重新同步之后进行。 resume-sync 取消设置本地同步暂停标志。 new-current-uuid 生成新的当前 UUID并旋转所有其他UUID值。这可以用来缩短集群的初始再同步。 有关更多详细信息，请参阅drbdsetup联机帮助页。 dstate 以local/peer形式显示后备存储设备的当前状态。 如：UpToDate/UpToDate hidden-commands 显示所有命令没有记录的命令。 [root@imoyao ~]# drbdadm hidden-commands These additional commands might be useful for writing # 写脚本或许有用 nifty shell scripts around drbdadm: sh-nop sh-resources sh-resource sh-mod-parms sh-dev sh-udev sh-minor sh-ll-dev sh-md-dev sh-md-idx sh-ip sh-lr-of sh-b-pri sh-status proxy-up proxy-down new-resource These commands are used by the kernel part of DRBD to # drbd内核 invoke user mode helper programs: before-resync-target after-resync-target before-resync-source pri-on-incon-degr pri-lost-after-sb fence-peer local-io-error pri-lost initial-split-brain split-brain out-of-sync These commands ought to be used by experts and developers: # 开发人员 sh-new-minor new-minor suspend-io resume-io set-gi new-current-uuid check-resize drbddisk.8TODO drbdsetup.8-配置内核模块TODO 版本信息本文档针对DRBD发行版本8.4.0进行了修订。 作者由Philipp Reisner &#112;&#x68;&#105;&#x6c;&#105;&#112;&#112;&#46;&#114;&#101;&#105;&#115;&#x6e;&#x65;&#x72;&#64;&#108;&#105;&#110;&#x62;&#105;&#116;&#x2e;&#99;&#x6f;&#109;和Lars Ellenberg撰写&#108;&#x61;&#x72;&#x73;&#x2e;&#x65;&#x6c;&#x6c;&#x65;&#x6e;&#x62;&#101;&#x72;&#x67;&#64;&#x6c;&#x69;&#110;&#x62;&#x69;&#x74;&#x2e;&#x63;&#x6f;&#x6d;。中译版由imoyao首发于别院牧志（idealyard） 报告错误将错误报告给&#x64;&#114;&#x62;&#100;&#45;&#117;&#x73;&#101;&#114;&#x40;&#x6c;&#x69;&#x73;&#x74;&#x73;&#x2e;&#108;&#105;&#110;&#x62;&#105;&#x74;&#46;&#x63;&#x6f;&#109;。 版权版权所有2001-2011 LINBIT信息技术公司，Philipp Reisner，Lars Ellenberg。 这是免费软件; 请参阅复制条件的来源。 没有保修; 甚至不适用于适销性或针对特定用途的适用性。 推荐阅读drbd.conf （5）， drbd （8）， drbddisk （8）， drbdsetup （8）， drbdmeta （8）和DRBD项目网站 [1] 参考链接 DRBD 8.4 Manual Pages]]></content>
      <tags>
        <tag>DRBD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 DRBD 裂脑问题的总结]]></title>
    <url>%2Fblog%2F2018-05-27%2FSplit-Brain-Of-DRBD%2F</url>
    <content type="text"><![CDATA[裂脑一旦发生，需要及时排查问题所在，最大限度保护数据完整性。 什么是DRBD裂脑裂脑(split brain)实际上是指在某种情况下，由集群节点间的网络连接临时故障、集群软件管理干预或者是人为错误，导致两个节点都切换为主节点（primary）而断开连接。这种状态是一个潜在的有害状态，因为它意味着不能复制数据到对等节点，这样就可能导致两个节点的数据产生分歧，产生不可合并的分裂。 怎么判定裂脑查看日志信息如果DRBD出现裂脑，会在 /var/log/message 出现一条日志： Split-Brain detected but unresolved, dropping connection! 当发生split brain之后，如果查看连接状态，其中至少会有一个是StandAlone状态，另外一个可能也是StandAlone（如果是同时发现split brain状态），也有可能是 WFConnection 状态。 裂脑自动通知如果进行配置，DRBD会调用裂脑处理程序，当裂脑发生时就会被探测到。要配置这个程序，需要对资源/etc/drbd.d/global_common.conf添加如下配置： resource &lt;resource&gt; handlers { split-brain &lt;handler&gt;; ... } ... } &lt;handler&gt;可能是目前系统中一个可执行的文件。 Drbd自带一个裂脑处理程序脚本/usr/lib/drbd/notify-split-brain.sh。它可以通过电子邮件的方式发送到指定的地址。要配合程序发送信息到root@localhost（这假设是设置的系统管理员的邮件地址），配置如下： resource &lt;resource&gt; handlers { split-brain &quot;/usr/lib/drbd/notify-split-brain.sh root&quot;; ... } ... } 当配置已经在资源上进行修改（同步到两个节点上），就不需要添加其他的处理就可以启动处理程序。Drbd会在下一次检测到裂脑时直接调用该处理程序。 如果要配置真实可用的报警邮箱地址，则除了将上面的通知地址改为真实邮件地址: split-brain &quot;/usr/lib/drbd/notify-split-brain.sh foo@bar.com 还需要修改一下ssmtp配置文件： vim /etc/ssmtp/ssmtp.conf # 填写真实收件服务器信息 mailhub=idealyard.imoyao.com:25 更多配置参见 这里 世代标识符元组（GI）参见16.2. Generation Identifiers DRBD 将其备份的数据的更新变化过程比拟成人类世代繁衍的过程。每个时点同一个双机的DRBD的两个节点上的数据都来自于同一份原始数据，我们可认为这个时点上两分数据源于同一祖先。主备节点的DRBD都会用一个叫作GI(Generation ID)的标识符来标识当前的数据是哪个世代的，同样也会记录最近两个数据祖先的GI用于追朔当前数据的历史来源。DRBD可以据此来判断两个节点是否是属于同一个双机,因为同一个双机的两份数据应该是从同一个祖先而来。GI作为DRBD的内部机制主要被用来： 确定这两个节点是否是事实上的同一个集群的成员（而不是意外连接的两个节点）； 确定触发全盘同步（full re-synchronization）还是只触发部分同步（partial re-synchronization）。 确定后台重新同步的方向（如果需要全盘同步）； 确定裂脑。 数据迭代当出现下列情形里DRBD会生成一个新的GI，用来标识新一代的数据： 第一次全盘同步时； 一个Disconnected的资源转换为Primary时； 一个Primary的资源转换为Disconnected时。 因此,我们可以总结出：只要一个DRBD资源处于Connected的状态，并且两边磁盘的状态为UpToDate，那么此DRBD资源在两个节点上的GI一定是一样的。此结论反过来也同样成立。请注意，当前实现使用最低位来编码节点的角色(Primary/Secondary)。 因此，即使它们被认为具有相同的数据生成，最低位在不同节点上也可能不同。 每个新的数据生成都由一个8字节的通用唯一标识符（UUID）来标识。 GI元祖DRBD在本地资源元数据中保存有关当前和历史数据生成的四条信息： 当前UUID(C-UUID)从本地节点的角度来看，这是当前数据生成的生成标识符。 当资源被连接并完全同步时，当前UUID在节点之间是相同的。 位图UUID(B-UUID)这是磁盘上同步位图跟踪的生成的UUID更改。 作为磁盘上的同步位图本身，此标识符仅在断开模式下才有用。 如果资源已连接，则此UUID始终为空（零）。 两个历史UUID 这些是当前之前两个数据世代的标识符。 上一代数据的UUID(H1-UUID)； 最近第二代数据的UUID(H2-UUID)，即上一代数据的上一代数据的UUID。 总的来说，这四个项目被称为代码标识符元组，或简称为GI元组。 GI如何变化？ 开始新的数据生成代 当节点与其对等方失去连接时（网络故障或人工干预都有可能），DRBD将按照以下方式修改其本地生成标识符： 为新的数据代生成新的UUID，变为主节点的C-UUID； 之前的UUID现在指向位图（B-UUID）以跟踪数据变化，因此它成为主节点的新位图UUID； 备节点GI元祖保持不变。 开始重新同步 在开始重新同步时，DRBD在本地代标识符上执行如下修改： 在同步源端的当前UUID（C-UUID）保持不变； 同步源端的位图UUID轮转为第一历史UUID（H1-UUID）； 同步源端生成新的位图UUID（B-UUID）; 该UUID（应指同步源端生成的B-UUID）变为同步目标端的新的当前UUID（C-UUID）； 同步目标端的位图UUID（B-UUID）和历史UUID（H1-UUID,H2-UUID）保持不变。 重新同步结束 当重新同步结束后，将执行以下更改： 同步源端当前UUID(C-UUID)保持不变； 同步源端的位图UUID(B-UUID)轮转为第一历史UUID（H1-UUID），同时该UUID(指H1-UUID)轮转为第二历史UUID(现有的第二历史uuid被丢弃)； 同步源端的位图UUID(B-UUID)清空（置零）； 同步目标端采用同步源端整个GI元祖。 当节点之间建立连接之后，两个节点之间会交换当前可用的代标识符,然后根据比对的结果采取相应的操作。以下是可能的几种结果： 两个节点上的当前UUID(C-UUID)都为空 本地节点检测到它的当前UUID和对方的当前UUID都是空的。这通常是发生于尚未启动初始完全同步的新配置资源的正常情况。此时没有同步发生;须手动人为触发启动。 单一节点上的当前UUID(C-UUID)为空 本地节点检测到对方的当前UUID为空，而其本身非空。这是新配置资源的正常情况，此时初始全盘同步刚刚触发，本地节点被选为初始同步源（sync source）。 DRBD将磁盘上的同步位图(sync bitmap)中的所有位全部置位（意味着它认为整个设备不同步），并开始将其作为同步源同步。相反，（即本地当前UUID为空，对等节点非空），除了本地节点成为同步目标（sync target）之外，DRBD执行相同的步骤。 当前UUID(C-UUID)相等 本地节点检测到它的当前UUID和对等节点的当前UUID非空且相等时。这是资源在secondary状态进入断开连接（disconnected）模式时的正常情况，并且在断开连接时并未在任一节点上升为 primary 状态。此时不会触发同步，因为两边的数据一致，没有必要。 位图UUID（B-UUID）匹配对等节点的当前UUID（`C-UUID`） 本地节点检测到其位图UUID匹配对等节点的当前UUID，且对等节点的位图UUID为空。这是本地节点处于 primary 状态，次要节点故障后正常且预期的情况。这意味着对端在此期间永远不会变为primary状态，并始终以相同的数据生成为前提运行。 DRBD此时以本地节点作为同步源（sync source）启动正常的后台重新同步（re-sync）。相反，如果本地节点检测到其位图UUID为空，且对等节点的位图与本地节点的当前UUID匹配，那么这是本地节点失败后的正常和预期情况。同样地，DRBD此时启动正常的后台重新同步，只不过本地节点成为同步目标（sync target）。 当前UUID(C-UUID)匹配对等节点的历史UUID（h-UUID） 本地节点检测到其当前UUID与对等节点的历史UUID之一(h1/h2)匹配。这意味着尽管两个数据集共享一个共同的祖先且对等节点具有最新的数据，但保存在对等节点的位图中的信息已过时并且不可用。因此，简单的正常同步不够的。 DRBD此时将整个设备标记为未同步（out-of-sync）并启动以本地节点作为同步目标（sync target）的全盘后台重新同步。在相反的情况下（本地节点的某个历史UUID与对等节点的当前UUID相匹配），除了本地节点成为同步源（sync source）之外，DRBD执行相同的步骤。 位图UUID（B-UUID）匹配，当前 UUID(C-UUID)不匹配 本地节点检测到其当前UUID与对等节点的当前UUID不同且位图UUID匹配。这是裂脑（split brain）的一种情况，两份数据有相同的父代。这意味着DRBD可以调用裂脑自动恢复策略进行数据恢复（如果已配置）。否则，DRBD断开连接并等待手动恢复。 当前UUID（C-UUID）和位图UUID(B-UUID)都不匹配 本地节点检测到它的当前UUID与对等节点的当前UUID不同，并且位图UUID不匹配。这是两份数据与无关父代产生的一种裂脑，因此即使配置了自动恢复策略也没有意义。 DRBD处于断开连接并等待手动恢复状态。 没有UUID匹配 最后，如果DRBD未能检测到两个节点之间的GI元组中的单个元素匹配，则会记录关于无关数据（unrelated data）的警告并断开连接。这是DRBD的防范措施，可防止之前无关联的两个集群节点的意外连接导致数据破坏。 以上逻辑使用代码表示如下： empty_uuid = &#39;0000000000000000&#39; def slice_seq(seq): &quot;&quot;&quot; 对GI元祖内元素进行切片操作 :param seq: GI元祖 :return:type:list &quot;&quot;&quot; global empty_uuid sliced_seq = [item[:-1] if item != empty_uuid else item for item in seq] return sliced_seq def cmp_both(seqa,seqb): for i in seqa: if i not in seqb: return 1 return 0 def get_gi_action(drbdname): &quot;&quot;&quot; 调用&#39;drbdadm get-gi DRBDNAME&#39;命令获取drbd的 GI(Generation ID) 信息 :param drbdname:type:str,drbd名称 like:&#39;drbds1/drbdn301&#39; :return:获取正常返回元祖(c_uuid, b_uuid, h1_uuid, h2_uuid)，获取失败返回None &quot;&quot;&quot; get_gi_cmd = &quot;drbdadm get-gi %s |awk -F: &#39;{print $1,$2,$3,$4}&#39;&quot;%(drbdname) retcode,proc = utils.cust_popen(get_gi_cmd) message = proc.stderr.read(), proc.stdout.read() retstr = message[1] if retstr: c_uuid,b_uuid,h1_uuid,h2_uuid = tuple(retstr.split()) return c_uuid,b_uuid,h1_uuid,h2_uuid else: debug.write_debug(debug.LINE(), &quot;peradrbd&quot;, message) return None def get_remote_gi(params): rtndata = {} result = {} drbdname = &#39;drbdname&#39; in params and params[&#39;drbdname&#39;] or &#39;&#39; if drbdname: if hasthedrbd(drbdname): gi_uuids = get_gi_action(drbdname) if gi_uuids is not None: rtndata[&#39;state&#39;] = &#39;0&#39; result[&#39;message&#39;] = &#39;&#39; result[&#39;gi_id&#39;] = gi_uuids else: rtndata[&#39;state&#39;] = &#39;1&#39; result[&#39;message&#39;] = &#39;11069&#39; # 获取 gi_id 出错 result[&#39;gi_id&#39;] = None else: rtndata[&#39;state&#39;] = &#39;1&#39; result[&#39;message&#39;] = &#39;11060&#39; # the drbd not found rtndata[&#39;result&#39;] = result else: rtndata = {&#39;state&#39;: &#39;1&#39;, &#39;result&#39;: {&#39;message&#39;: &#39;11059&#39;}} # drbdname error return rtndata def exchange_gi_process(drbdname): &quot;&quot;&quot; see:https://docs.linbit.com/docs/users-guide-8.4/#s-gi (16.2.4. How DRBD uses generation identifiers) :param drbdname: :return:type:str &quot;&quot;&quot; local_gis = get_gi_action(drbdname) remote_gis = None global remoteip retresult = hautils.socketclient(ip=remoteip, **{&#39;target&#39;: &#39;drbd&#39;, &#39;op&#39;: &#39;getremotegi&#39;, &#39;params&#39;: {&#39;drbdname&#39;:drbdname}}) if retresult: if retresult[&#39;state&#39;] == &#39;0&#39;: remote_gis = retresult[&#39;result&#39;][&#39;gi_id&#39;] drbd_next = &#39;&#39; if local_gis is not None and remote_gis is not None: local_gis_sliced = slice_seq(local_gis) remote_gis_sliced = slice_seq(remote_gis) global empty_uuid print(&#39;sliced&#39;, local_gis_sliced, remote_gis_sliced) if local_gis_sliced[0] == empty_uuid and remote_gis_sliced[0] == empty_uuid: drbd_next = &#39;no_sync:(manual_sync)&#39; elif local_gis_sliced[0] == empty_uuid or remote_gis_sliced[0] == empty_uuid: if remote_gis_sliced[0] == empty_uuid and local_gis_sliced[0] != empty_uuid: drbd_next = &#39;full_re_sync:(local_source)&#39; elif local_gis_sliced[0] == empty_uuid and remote_gis_sliced[0] != empty_uuid: drbd_next = &#39;full_re_sync:(local_target)&#39; elif local_gis_sliced[0] != empty_uuid and remote_gis_sliced[0] != empty_uuid and local_gis_sliced[0] == remote_gis_sliced[0]: drbd_next = &#39;consistent:(both_secondary)&#39; elif local_gis_sliced[1] == remote_gis_sliced[0] and remote_gis_sliced[1] == empty_uuid: drbd_next = &#39;partial_re_sync:(local_source)&#39; elif local_gis_sliced[1] == empty_uuid and remote_gis_sliced[1] == local_gis_sliced[0]: drbd_next = &#39;partial_re_sync:(local_target)&#39; elif local_gis_sliced[0] in [remote_gis_sliced[2], remote_gis_sliced[3]]: drbd_next = &#39;full_re_sync:(local_target)&#39; elif remote_gis_sliced[0] in [local_gis_sliced[2], local_gis_sliced[3]]: drbd_next = &#39;full_re_sync:(local_source)&#39; elif local_gis_sliced[0] != remote_gis_sliced[0]: if local_gis_sliced[1] == remote_gis_sliced[1]: drbd_next = &#39;split_brain:(auto_recover_able)&#39; elif local_gis_sliced[1] != remote_gis_sliced[1]: drbd_next = &#39;split_brain:(wait_for_manual_recover)&#39; elif cmp_both(local_gis_sliced,remote_gis_sliced): drbd_next = &#39;unrelated_data:(wait_for_manual_recover)&#39; else: debug.write_debug(debug.LINE(), &quot;peradrbd&quot;, (local_gis_sliced, remote_gis_sliced)) else: debug.write_debug(debug.LINE(), &quot;peradrbd&quot;, (local_gis,remote_gis)) return drbd_next 注意： 经分析官方文档中的’matches’并不是完全相等，而 ‘UUID is always empty (zero)’ 是指 “‘0’*16” 的字符串 如何模拟一个 Split-Brain状态 往主节点写入大文件，在未写入完前停止备节点的DRBD；# on secondary drbdadm down drbdxx 停止主节点的DRBD；# on primary drbdadm down drbdxx 启动备节点的DRBD，设置为主节点；# on secondary drbdadm up drbdxx drbdadm primary drbdxx 启动原主节点的DRBD，这时发现它的状态就是StandAlone Secondary/Unknown UpToDate/DUnknown，Split-Brain 情况出现。# on primary drbdadm up drbdxx 解决DRBD裂脑状态设置自动修复5.17.2. Automatic split brain recovery policies 警告：配置DRBD自动修复裂脑（或其他状况）导致的数据分歧情况可能是正在配置的数据丢失，如果你不知道你在干什么，那最好别干。（NO ZUO NO DIE） 提示 ：您更应该查看系统防护策略，集群管理集成和冗余集群管理器通信连接状态，以避免出现数据分歧。（防患于未然而不是亡羊补牢）在启用和配置DRBD的自动裂脑恢复策略之前，您必须了解DRBD为此提供了多种配置选项。 DRBD根据检测到裂脑时主节点（Primary role）的数量应用其裂脑恢复程序。为此，DRBD检查以下关键字，这些关键字均可在资源的网络配置部分中找到： after-sb-0pri裂脑被检测到的同时该资源在任一节点不是主节点。对于这种状况，DRBD可以理解以下关键字： disconnect: 不自动恢复，只调用裂脑通知程序（如果已配置），断开连接并保持断开； discard-younger-primary: 丢弃并回滚最后升主节点的改动； discard-least-changes: 丢弃并回滚修改更少节点的修改； discard-zero-changes: 如果有某一节点一点未改动，只需应用对另一主机所做的修改并继续； after-sb-1pri裂脑刚被检测到的同时该资源在一个节点上是主节点。对于这种状况，DRBD理解以下关键字： disconnect:同上 consensus：应用上一步的策略之后，如果裂脑受害者可以选择拆分则会自动解决。否则，与disconnect指令相同。 call-pri-lost-after-sb：应用上一步的策略之后，如果裂脑受害者节点可以选择拆分则调用pri-lost-after-sb处理程序，该处理程序必须在处理程序中进行配置，并且需要强制从集群中删除该节点。 discard-secondary：将从端（Secondary role）节点视为裂脑受害者。 after-sb-2pri裂脑刚被检测到时该资源在两个节点都处于主端。该选项接受与除discard-secondary 和 consensus 之外与 after-sb-1pri 相同的关键字。 提示：DRBD还可以理解这三个选项下额外的关键字，这些关键字在这里被省略，因为它们很少被使用。请参阅drbd.conf的手册页以获取有关裂脑恢复关键字的详细信息，此处不再讨论。例如，用作双主模式下GFS或OCFS2文件系统的块设备的资源可能会将其恢复策略定义如下： resource &lt;resource&gt; { handlers { split-brain &quot;/usr/lib/drbd/notify-split-brain.sh root&quot; # 脚本通知root用户，此处可以使用邮件提醒 ... } net { after-sb-0pri discard-zero-changes; after-sb-1pri discard-secondary; after-sb-2pri disconnect; ... } ... } 手动恢复6.3. Manual split brain recovery 在检测到裂脑后，一个节点将始终使资源处于StandAlone连接状态。另一个可能也处于StandAlone状态（如果两个节点同时检测到裂脑）或WFConnection（如果某方节点在另一节点检测到裂脑之前断开连接）。 此时，除非已将DRBD配置为自动从裂脑状态中恢复，否则必须通过选择一个节点进行手动干预，该节点的修改将被丢弃（此节点称为裂脑受害者）。这个干预使用下面步骤完成： 裂脑受害者需要处于StandAlone的连接状态，否则以下命令将返回错误。您可以通过发出以下内容确保它是StandAlone的： drbdadm disconnect &lt;resource&gt; drbdadm secondary &lt;resource&gt; drbdadm connect --discard-my-data &lt;resource&gt; # 8.4+ if 8.3,use &#39;drbdadm -- --discard-my-data connect &lt;resource&gt;&#39; instead 在另一个节点（裂脑幸存者）上，如果它的连接状态也是StandAlone，你可以输入： drbdadm connect &lt;resource&gt; 如果节点已处于WFConnection状态，则可以省略此步骤;它会自动重新连接。 如果受裂脑影响的资源是堆叠资源，请使用drbdadm --stacked而不是drbdadm。 连接后，裂脑受害者立即将其连接状态更改为SyncTarget，并将其导致裂脑的修改由其余主节点的数据覆盖。 裂脑受害者不会引发全盘同步。相反，它的局部修改已经被回滚，对裂脑幸存者的任何修改都会传递给受害者。重新同步完成后，裂脑被视为已解决（resolved），两个节点再次形成完全一致的冗余复制存储系统（DRBD）。 参考链接 User’s Guide 8.4.x 关于DRBD v8.3的同步机制 一次DRBD裂脑行为的模拟 drbd裂脑处理 | IT瘾 http://www.3mu.me/%E4%BB%80%E4%B9%88%E6%98%AFdrbd%E8%84%91%E8%A3%82%E5%8F%8A%E5%A6%82%E4%BD%95%E6%A8%A1%E6%8B%9Fdrbd%E8%84%91%E8%A3%82/ drbd中metadata的理解(原创) – 蚊子世界http://www.wenzizone.cn/2009/10/29/drbd%e4%b8%admetadata%e7%9a%84%e7%90%86%e8%a7%a3%e5%8e%9f%e5%88%9b.html]]></content>
      <tags>
        <tag>DRBD</tag>
        <tag>裂脑</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于在 Python 中 MySQL 的 WHERE 子句中执行 IN 操作（list，tuple）的问题]]></title>
    <url>%2Fblog%2F2018-05-10%2Fexecuting-select-where-in-using-mysqldb%2F</url>
    <content type="text"><![CDATA[今天在写代码的时候，有一处查询语句需要执行 IN 操作，结果直接join操作会出错。 list_of_datas = [u&#39;sde&#39;, u&#39;sdf&#39;, u&#39;sdb&#39;, u&#39;sdc&#39;] sql = &quot;SELECT DiskId,Name,Sg,PhyId,ExpanderId,EProduct FROM Disk WHERE Used=&#39;2&#39; AND Name IN (%s)&quot; % &#39;,&#39;.join(list_of_datas) 执行结果： SELECT DiskId, Name, Sg, PhyId, ExpanderId , EProduct FROM Disk WHERE Used = &#39;2&#39; AND Name IN (sde, sdf, sdb, sdc) 很明显与预期的结果是不一样的。因为 IN 操作中的选取字段应该是带引号的字符串，而不是直接显示的字符串。也就是说我们期望的WHERE子句中是WHERE Used = &#39;2&#39; AND Name IN (&#39;sde&#39;, &#39;sdf&#39;, &#39;sdb&#39;, &#39;sdc&#39;)形式。 sql1 = &quot;SELECT DiskId,Name,Sg,PhyId,ExpanderId,EProduct FROM Disk WHERE Used=&#39;2&#39; AND Name IN (%s)&quot; % &#39;,&#39;.join([&quot;&#39;%s&#39;&quot; % item for item in list_of_datas]) 执行结果： SELECT DiskId, Name, Sg, PhyId, ExpanderId , EProduct FROM Disk WHERE Used = &#39;2&#39; AND Name IN (&#39;sde&#39;, &#39;sdf&#39;, &#39;sdb&#39;, &#39;sdc&#39;) 至此，可以满足我们的要求。不过，由于上面字符化操作感觉有点暴力，我们可以稍微改进一下： format_strings= &#39;,&#39;.join([repr(item) for item in list_of_datas]) print(format_strings) 执行结果： u&#39;sde&#39;,u&#39;sdf&#39;,u&#39;sdb&#39;,u&#39;sdc&#39; 此时 SQL 语句变成: SELECT DiskId,Name,Sg,PhyId,ExpanderId,EProduct FROM Disk WHERE Used=&#39;2&#39; AND Name IN (u&#39;sde&#39;,u&#39;sdf&#39;,u&#39;sdb&#39;,u&#39;sdc&#39;) 这个是没办法正常查询出结果的，因为查询字段是 unicode 编码。 format_unicode_strings = &#39;,&#39;.join([repr(item.encode(&#39;utf-8&#39;)) if isinstance(item,unicode) else repr(item) for item in list_of_datas]) 此时结果满足我们的要求： SELECT DiskId, Name, Sg, PhyId, ExpanderId , EProduct FROM Disk WHERE Used = &#39;2&#39; AND Name IN (&#39;sde&#39;, &#39;sdf&#39;, &#39;sdb&#39;, &#39;sdc&#39;) 至此，收工。 因为公司的代码封装函数是只能执行真正的 SQL 语句的，所以只能用上面的方法，查询网络上别人的解决方案发现下面的写法，以备参考。 &gt;&gt;&gt; alist = [&#39;1.1.1.1&#39;,&#39;2.2.2.2&#39;,&#39;3.3.3.3&#39;] &gt;&gt;&gt; select_str = &#39;select * from server where ip in (%s)&#39; % &#39;,&#39;.join([&#39;%s&#39;] * len(alist)) &gt;&gt;&gt; select_str &#39;select * from server where ip in (%s,%s,%s)&#39; # 执行sql查询 cursor.execute(select_str,a) 后面的写法有很多种，比如： args = [1, 2, 3] in_p = &#39;, &#39;.join((map(lambda x: &#39;%s&#39;, args))) realsql = sql % in_p cursor.execute(realsql, args) 再比如： args = [1, 2, 3] in_p = &#39;, &#39;.join(itertools.repeat(&#39;%s&#39;, len(args))) cursor.execute(sql % in_p, args) 完整示例代码: #!/usr/bin/env python # -*- coding: utf-8 -*- # Created by imoyao at 2018/5/18 17:17 import itertools import MySQLdb def excute_sql(sql): db = MySQLdb.connect(host=&quot;localhost&quot;, user=&quot;imoyao&quot;, passwd=&quot;111111&quot;, db=&quot;ODSP&quot;, charset=&quot;utf8&quot;) cr = db.cursor() cr.execute(sql) data = cr.fetchall() cr.close() db.close() return data def excute_sql_datas(sqlstr, tupledata): db = MySQLdb.connect(host=&quot;localhost&quot;, user=&quot;imoyao&quot;, passwd=&quot;111111&quot;, db=&quot;ODSP&quot;, charset=&quot;utf8&quot;) cr = db.cursor() cr.execute(sqlstr,tupledata) data = cr.fetchall() cr.close() db.close() return data if __name__ == &#39;__main__&#39;: list_of_datas = [u&#39;sde&#39;, u&#39;sdf&#39;, u&#39;sdb&#39;, u&#39;sdc&#39;] format_strings = &#39;,&#39;.join( [repr(item.encode(&#39;utf-8&#39;)) if isinstance(item, unicode) else repr(item) for item in list_of_datas]) sql = &quot;SELECT DiskId,Name,Sg,PhyId,ExpanderId,EProduct FROM Disk WHERE Used=&#39;2&#39; AND Name IN (%s)&quot; % format_strings print(excute_sql(sql)) print(&#39;*&#39;*40) sql2 = &quot;SELECT DiskId,Name,Sg,PhyId,ExpanderId,EProduct FROM Disk WHERE Used=&#39;2&#39; AND Name IN (%s)&quot; # format_strings2 = &#39;, &#39;.join(map(lambda x: &#39;%s&#39;, list_of_datas)) # format_strings2 = &#39;, &#39;.join([&#39;%s&#39;] * len(list_of_datas)) format_strings2 = &#39;, &#39;.join(itertools.repeat(&#39;%s&#39;, len(list_of_datas))) sqlstr = sql2 % format_strings2 print(excute_sql_datas(sqlstr, list_of_datas)) 参考链接： python mysql where in 对列表（list,,array）问题 - CSDN博客 python - Executing “SELECT … WHERE … IN …” using MySQLdb - Stack Overflow]]></content>
      <tags>
        <tag>Python</tag>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 Python 中的下划线用法的记录]]></title>
    <url>%2Fblog%2F2018-04-28%2Fthe-underline-of-Python%2F</url>
    <content type="text"><![CDATA[Py乙己孔乙己自己知道不能和架构师谈天，便只好向实习生说话。 有一回对我说道，“你写过Python么？”我略略点一点头。 他说，“写过代码，……我便考你一考。Python中的下划线，怎样用的？” 我想，搬砖一样的人，也配考我么？便回过脸去，不再理会。 孔乙己等了许久，很恳切的说道，“不能写罢？……我教给你，记着！这些用法应该记着。将来做面试官的时候要用。” 我暗想我和面试官的等级还很远呢，而且我们面试官也从不将这些问题拿来考应聘者；又好笑，又不耐烦，懒懒的答他道，“谁要你教，不就是命名变量，增加代码的可读性吗？” 孔乙己显出极高兴的样子，将两个指头的长指甲敲着键盘，点头说，“对呀对呀！……下划线有四种写法，你知道么？” 我愈不耐烦了，努着嘴走远。孔乙己刚用纸巾擦了擦键盘上的咖啡渍，想在IDE里写代码，见我毫不热心，便又叹一口气，显出极惋惜的样子。 正文 在交互式解释器中获取上一个语句执行的结果； &gt;&gt;&gt; 1+1 2 &gt;&gt;&gt; _ 2 &gt;&gt;&gt; _ * 5 10 用来在函数、模块、包、变量名中分隔单词，增加可读性； var_foo_bar = &#39;hello,world!&#39; 内部使用的变量、属性、方法、函数、类或模块，（约定）又称为内部实现； # 假定存在foo.py中定义变量： _var = 9527 # 在bar.py中导入 from foo import * # 不会导入以下划线开头的对象 print(_var) # 返回： NameError: name &#39;_var&#39; is not defined 当然也可以强制导入（不推荐） from foo import _var # Access to a protected member _var of a module print(_var) # 返回： 9527 避免与 Python 保留的关键字冲突（约定）； Tkinter.Toplevel(master, class_=&#39;ClassName&#39;) # 注意class为Python內建名称 在类内的私有变量（private），类外部无法直接使用原名称访问，需要通过instance._ClassName__var的形式访问（name mangling）； class Person(object): __say_hello = &#39;Hello,world&#39; def __init__(self, name, age): self.name = name self.age = age def get_name(self): return self.name def get_age(self): return self.age if __name__ == &#39;__main__&#39;: pi = Person(&#39;Peter&#39;, 26) # print(pi.__say_hello) # AttributeError: &#39;Person&#39; object has no attribute &#39;__say_hello&#39; print(pi._Person__say_hello) print(pi.get_age()) 我们可以使用dir(pi)看一下对象中的中的属性和方法： [&#39;_Person__say_hello&#39;, &#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__doc__&#39;, &#39;__format__&#39;, &#39;__getattribute__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__module__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;age&#39;, &#39;get_age&#39;, &#39;get_name&#39;, &#39;name&#39;] 这里 Python 解释器触发名称修饰，它这样做是为了防止变量在子类中被重写。 # 新建一个集成Person的AI类 class AI(Person): __say_hello = &#39;ALL in AI&#39; pass if __name__ == &#39;__main__&#39;: ai_attr = [&#39;ALL in AI&#39;]*3 ai = AI(*ai_attr) print(dir(ai)) 我们可以看到继承关系： # 返回 [&#39;_AI__say_hello&#39;, &#39;_Person__gender&#39;, &#39;_Person__say_hello&#39;, &#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__doc__&#39;, &#39;__format__&#39;, &#39;__getattribute__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__module__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_age&#39;, &#39;name&#39;] 这点在 《Python Cookbook》- 8.5 在类中封装属性名 中对于单下划线和双下划线的使用场景也有提及和解释： 大多数而言，你应该让你的非公共名称以单下划线开头。但是，如果你清楚你的代码会涉及到子类，并且有些内部属性应该在子类中隐藏起来，那么才考虑使用双下划线方案。 在类内的保护变量（这一条存疑）； _var_ Python 内置的“魔法”方法或属性，你也可以自己定义，但强烈 不推荐。比如： __init__, __file__, __main__ 作为内部使用的一次性变量； 通常在循环里使用,比如： foo_list = [_ for _ in range(10)] 或是用作占位，不实际使用的变量,比如： for _, a in [(1,2),(3,4)]: print a i18n 里作为 gettext() 的缩写； _() 用来分隔数值以增加可读性（Python 3.6 新增）； &gt;&gt;&gt; num = 1_000_000 &gt;&gt;&gt; num 1000000 1_000_000 参考来源 PEP 8 – Style Guide for Python Code Python basic cheatsheet The Meaning of Underscores in Python – dbader.org Python中的下划线_有多少个意思？- 知乎 派森多一点Python中的dunder 参见这里 关于Python 编程的一个尴尬的事情是：有很多种双下划线。 例如，语法糖下面的标准方法名称具有 __getattr__ 这样的名称，构造函数是 __init__ ，内置运算符可以用 __add__ 重载，等等。 在 Django 框架中（至少在他们整合了 magic-removal 分支之前），对象关系映射器使用了名为 user__id__exact 的关键字参数。 双下划线的问题是很难向别人描述。 你怎么读 __init__ ？ “下划线下划线 init 下划线下划线”？ “双下划线 init 双下划线”？ 简单的 “init” 似乎漏掉了一些重要的东西。 我有一个解决方案：双下划线应该发音为 “dunder” 。 所以 __init__ 念成“dunder init dunder”，或者也可以简读为 “dunder init” 。 现在我期待某个人定义一下 “dunderhead” 是什么意思，haha……]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析Python中的延迟绑定问题]]></title>
    <url>%2Fblog%2F2018-04-10%2Flate-binding-of-Python%2F</url>
    <content type="text"><![CDATA[延迟绑定(late binding)闭包Python 使用中一个常见的困惑是 Python 在闭包(或在周围全局作用域（surrounding global scope）)中绑定变量的方式。你所写的函数： def multi_expression(): return [lambda n: n*i for i in range(5)] 你所期望的： if __name__ == &#39;__main__&#39;: print([mult(10) for mult in multi_expression()]) 一个包含五个函数返回值的列表，每个函数有它们自己的封闭变量 i 乘以它们的参数，得到: [0, 10, 20, 30, 40] 而实际结果是： [40, 40, 40, 40, 40] 创建了五个函数，它们全都是 4 乘以 n 。Python 的闭包是迟绑定 。这意味着闭包中用到的变量的值是在内部函数被调用时查询得到的。在这里, 每当调用任何函数返回时, i 的值是调用时在周围作用域（ surrounding scope）中查询到的。到那个时候，循环已经完成， i 的值最终变成 4 。关于这个陷阱有一个普遍严重的误解，它很容易被甩锅给 Python 的 lambda表达式。实际上， lambda 表达式是被冤枉滴。我们尝试把它改写成普通函数： def multi_func(): foo = [] for i in range(5): def func(n): return n * i foo.append(func) return foo 为了实现目标，你应该这样： 最一般的解决方案可以说是有点取巧（ hack ）。由于 Python 拥有在前文提到的为函数默认参数赋值的行为（参见 可变默认参数 ）,你可以像下面这样创建一个立即绑定参数的闭包： def multi_expression_hack(): return [lambda n, i=i: n * i for i in range(5)] # 此处用法参见《Python Cookbook》7.7 匿名函数捕获变量值 if __name__ == &#39;__main__&#39;: print([func(10) for func in multi_expression_hack()]) 或者，你可以使用 functools.partial 函数（偏函数）： from functools import partial from operator import mul def partial_func(): return [partial(mul, i) for i in range(5)] if __name__ == &#39;__main__&#39;: print([func(10) for func in partial_func()]) 优雅的写法，直接用生成器推导式： def gen_expression(): return (lambda n: n * i for i in range(5)) if __name__ == &#39;__main__&#39;: print([gen(10) for gen in gen_expression()]) 利用 yield 的惰性求值思想编写生成器函数： def gen_func(): for i in range(5): yield lambda n: i * n if __name__ == &#39;__main__&#39;: print([gen(10) for gen in gen_func()]) 当陷阱不是一个陷阱有时, 你预期闭包是这样的（迟绑定的表现形式）。延迟绑定在多数情况下是正常的。不幸的是, 循环创建独特的函数可能会导致未知的小问题。 派森多一点关于生成器的惰性求值，我们可以看点简单的例子： # coding=utf-8 def add(a, b): return a + b def gen(n): for i in range(n): yield i def main(m_num, m_gen_num): base = gen(m_gen_num) for n in range(m_num): base = (add(i, n) for i in base) return base if __name__ == &#39;__main__&#39;: num = 5 gen_num = 10 print(list(main(num, gen_num))) 返回结果： [90, 91, 92] 如果我们对之前改写的multi_func()函数再稍微改写一下，让内部函数传值*args会怎么样？ def multi_func_starred(): foo = [] for i in range(5): def func(*n): return n * i foo.append(func) return foo if __name__ == &#39;__main__&#39;: print([func(10) for func in multi_func_starred()]) 返回结果： [(10, 10, 10, 10), (10, 10, 10, 10), (10, 10, 10, 10), (10, 10, 10, 10), (10, 10, 10, 10)] 实际上，*args相当于一个生成器推导式，这点很容易验证： def multi_expression_starred(): # print(type(lambda *n: n*i for i in range(5))) # 去掉注释 &gt;&gt;&gt;: &lt;class &#39;generator&#39;&gt; return [lambda *n: n * i for i in range(5)] if __name__ == &#39;__main__&#39;: print([func(10) for func in multi_expression_starred()])]]></content>
      <tags>
        <tag>Python</tag>
        <tag>延迟绑定</tag>
        <tag>生成器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python环境管理介绍]]></title>
    <url>%2Fblog%2F2018-01-18%2Fpython-env-introduce%2F</url>
    <content type="text"><![CDATA[venv, pyvenv, pyenv, virtualenv, virtualenvwrapper, pipenv 等工具的区别与介绍。项目开发中可能需要用到不同版本的Python及相关的开发环境。比如Python2及Python3，或者有的项目需要 Django1.5 ，有的需要2.0，这个时候借助一些工具，往往可以达到事半功倍的效果。 第三方库：virtualenvvirtualenv是一个非常流行的工具，为Python库创建独立的Python环境。如果你不熟悉这个工具，我强烈建议你学习它，因为它是一个非常有用的工具，我将在这个答案的其余部分对此进行比较。 它通过在一个目录（例如：env/）中安装一堆文件，然后修改PATH环境变量来为自定义bin目录（例如：env/bin/）添加前缀。 python或python3二进制文件的精确拷贝会被放置在这个目录中，但Python被编程为首先在环境目录中查找相对于其路径的库。它不是Python标准库的一部分，但是获得PyPA（Python Packaging Authority）正式称赞。激活之后，你就可以使用pip在虚拟环境中安装软件包。 virtualenvwrappervirtualenvwrapper是virtualenv的一组扩展（参见文档）。它提供例如mkvirtualenv、lssitepackages这样的命令，特别是workon命令，它可以在不同的virtualenv目录之间切换。如果你想要多个virtualenv目录，这个工具特别有用。 pyenvpyenv是Python的版本管理器,用于隔离Python版本。例如，你可能想要针对Python 2.6,2.7,3.3,3.4和3.5测试你的代码，因此你需要在不同Python版本之间进行切换。一旦激活，它就会在PATH环境变量前加上~/.pyenv/shims，其中有一些与Python命令（python，pip）匹配的特殊文件。这些不是Python提供的命令的副本;它们是根据PYENV_VERSION环境变量或.python-version文件或~/.pyenv/version文件决定运行哪个版本的Python的特殊脚本。 pyenv也使下载和安装多个Python版本的过程变得更简单，使用命令pyenv install即可。 pyenv-virtualenvpyenv-virtualenv是pyenv的一个插件，和pyenv一样，允许你在同一时间方便地使用pyenv和virtualenv。但是，如果你使用Python 3.3或更高版本，则pyenv-virtualenv会尝试运行python -m venv（如果可用），而不是virtualenv。如果你不想使用便利功能，则可以搭配使用virtualenv和pyenv而不使用pyenv-virtualenv。 pyenv-virtualenvwrapperpyenv-virtualenvwrapper是pyenv的一个插件，可以很方便地将virtualenvwrapper集成到pyenv中。 pipenvpipenv是Python的包管理器。由Kennetth Reitz（requests的作者）编写维护，是我们上面提到的这些项目里面最新的。它的目标是在命令行中将Pipfile、pip和virtualenv合并为一个命令。 标准库：pyvenvpyvenv是一个Python 3附带的脚本，但在Python 3.6中被弃用，（参见这里）因为它有问题（暂且不说名字还容易造成混淆）。在Python 3.6+中，实际上等价于命令python3 -m venv。 venvvenv是Python 3附带的一个包，你可以使用python3 -m venv运行（虽然由于某些原因，一些发行版把它分离成一个单独的发行包，比如Ubuntu / Debian上的python3-venv）。它的作用与virtualenv相似，工作方式也非常相似，但不需要复制Python二进制文件（Windows下除外）。如果你的代码不需要支持Python 2，可以使用它。在撰写本文时，Python社区似乎对virtualenv感到满意，venv相对来说比较小众。 参考链接1.Python - What is the difference between venv, pyvenv, pyenv, virtualenv, virtualenvwrapper, pipenv, etc? - Stack Overflow 2.Pipenv &amp; Virtual Environments — The Hitchhiker’s Guide to Python]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7环境下配置DRBD]]></title>
    <url>%2Fblog%2F2018-01-11%2Fhow-to-configure-drbd-on-CentOS7%2F</url>
    <content type="text"><![CDATA[本文主要记录DRBD的配置过程和功能验证。 本文使用64位CentOS，基本环境： +-----------------------+ | +----------------------+ | [ DRBD_A (Server#1) ] | 10.10.17.18 | 10.10.17.19 | [DRBD_B (Server#2) ] | | node01 +--------------+---------------+ node02 | | | | | +-----------------------+ +----------------------+ DRBD 服务器A ：ip:10.10.17.18，hostname：DRBD_A DRBD 服务器B ：ip:10.10.17.19，hostname：DRBD_B 建立磁盘分区 分区之前 [root@DRBD_A ~]# lsblk # 查询块设备信息 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT fd0 2:0 1 4K 0 disk sda 8:0 0 16G 0 disk ├─sda1 8:1 0 500M 0 part /boot └─sda2 8:2 0 15.5G 0 part ├─centos_bogon-root 253:0 0 13.9G 0 lvm / └─centos_bogon-swap 253:1 0 1.6G 0 lvm [SWAP] sdb 8:16 0 5G 0 disk └─StorPool-SANLun10 253:2 0 2G 0 lvm sr0 11:0 1 1024M 0 rom drbd0 147:0 0 2G 1 disk 进行分区 [root@DRBD_A ~]# fdisk /dev/sdb # 在sdb上新建分区 Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table Building a new DOS disklabel with disk identifier 0xb25d5d26. Command (m for help): n # 新建 Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): Using default response p Partition number (1-4, default 1): First sector (2048-10485759, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-10485759, default 10485759): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): w # 写入 The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 分区之后 [root@DRBD_A ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT fd0 2:0 1 4K 0 disk sda 8:0 0 16G 0 disk ├─sda1 8:1 0 500M 0 part /boot └─sda2 8:2 0 15.5G 0 part ├─centos_bogon-root 253:0 0 13.9G 0 lvm / └─centos_bogon-swap 253:1 0 1.6G 0 lvm [SWAP] sdb 8:16 0 5G 0 disk ├─sdb1 8:17 0 1G 0 part # 新分区 └─StorPool-SANLun10 253:2 0 2G 0 lvm sr0 11:0 1 1024M 0 rom drbd0 147:0 0 2G 0 disk /media 修改配置文件更改DRBD全局配置首先根据需求更改DRBD全局配置/etc/drbd.d/global_common.conf: 此处可参阅另一篇文章：DRBD全局配置 创建DRBD配置文件由于DRBD是基于块设备的存储复制解决方案，所以此处使用Lun作为演示。 vi r0.res resource r0 { # DRBD device device /dev/drbd0; # block device disk /dev/StorPool/SANLun10; # 磁盘路径，若为disk则修改为/dev/sdb1 meta-disk internal; on DRBD_A { # IP address:port address 10.10.17.18:7788; } on DRBD_B { address 10.10.17.19:7788; } } 注意：本机主机名(hostname)和地址(ip)必须严格按照真实情况配置，两边.res文件内容尽量保持一致。 配置文件创建完成之后，在两个服务器上分别执行如下命令，创建DRBD资源，当然你也可以通过scp把配置文件拷过去，然后执行相关命令。 其中上述配置文件的meta-disk有三种记录方式：internal/device/device[index_num]。其中不管是哪种方式，metadata存放的分区不能格式化，哪怕使用internal时metadata和一般data在同一个分区也不能格式化该分区。 internal是将元数据也写入到数据分区的尾部，即数据和元数据同分区。如果指定的device没有给定index时，则表示元数据存储到该设备中。如果某节点指定device[index_num]，那么指定几次元数据分区索引就必须大于128M的几倍，例如上述文件中drbd1.longshuai.com节点指定了/dev/sdb1[0]，那么sdb1就必须大于128M，如果此时其他资源的节点也指定了同一台服务器的/dev/sdb1[1]，则指定了两次就必须大于256M。指定为internal和device时，元数据区的大小是drbd自行计算的。上面index的说法来自这里，具体没有实际验证。 drbdadm create-md r0 然后启动DRBD： drbdadm up r0 我在测试时没有操作下一步操作，但是数据也可以完成同步。查询了一下，网上说drbdadm up这个命令相当于attach、syncer、connect的总集合。但是后台使用systemctl status drbd获取到的状态还是inactive (dead)，欢迎大家提出自己的看法。 在两个服务器上分别启动DRBD服务： /etc/init.d/drbd start 把DRBD_A做为主服务器： # 无数据时 drbdadm primary r0 # 有数据时，把本端作为primary端，本地数据分发到其他节点。 drbdadm -- --overwrite-data-of-peer primary r0 使用如下命令查看DRBD服务的状态信息： /etc/init.d/drbd status #或者 drbd-overview 此时，写入DRBD_A端(/dev/drbd1)的数据都会同步到DRBD_B端。 测试数据同步Primary端 格式化drbd mkfs.xfs /dev/drbd0 挂载设备 mount /dev/drbd0 /media 写入数据 cd /media/ mkdir drbd_test cd drbd_test/ echo &quot;hello World&quot; &gt; hello.txt 卸载设备 cd ~ umount /media 本端降级 drbdadm secondary r0 Secondary端 从端升主 drbdadm primary r0 挂载设备 mount /dev/drbd0 /media 注意： 此时从端不需要再次格式化，否则数据丢失。 验证数据 cd /media ls cat ./drbd_test/hello.txt # 返回 hello World 参考来源 CentOS 7 : DRBD : Configure : Server World]]></content>
      <categories>
        <category>工作日常</category>
      </categories>
      <tags>
        <tag>DRBD</tag>
        <tag>Linux</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7下源码安装DRBD]]></title>
    <url>%2Fblog%2F2018-01-11%2Fhow-to-install-drbd-on-CentOS7%2F</url>
    <content type="text"><![CDATA[最近开发中又要用到DRBD做远程复制的功能，网上搜到很多都是yum安装的办法，这里记录一下源码安装的办法。 准备工作关闭防火墙systemctl disable firewalld systemctl stop firewalld 关闭SELinuxsed -i -e &quot;s/=enforcing/=disabled/g&quot; /etc/selinux/config setenforce 0 安装依赖yum -y update yum -y install gcc make automake autoconf libxslt libxslt-devel flex rpm-build wget 注意： 安装kernel-devel一定要和uname -r获取结果一致。 rpm -q kernel-devel uname -r # 3.10.0-327.el7.x86_64 返回的内核版本应当一致，否则建议用本地源安装kernel-devel。 下载/解压源码官方地址：https://www.linbit.com/en/drbd-community/drbd-download/ 旧版本：http://www.linbit.com/en/drbd-community/old-releases/ MORE：http://www.linbit.com/www.linbit.com/downloads/drbd/ 注意： 在DRBD 8.4.3(?)以上版本，对drbd和utils做了拆分，需要分别进行下载。 wget https://xxx.tar.gz 当然，如果需要你也可以通过我的分享下载编译好的rpm包（示例版本）： 链接: https://pan.baidu.com/s/1huncgDI 密码: b41i 解压下载的两个tar包tar -zxvf drbd-8.*.tar.gz tar -zxvf drbd-utils-*.tar.gz 编译rpm创建构建DRBD需要的目录mkdir -p rpmbuild/{BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS} 编译DRBD制作 rpm 包cd drbd-8.4.5/ make clean make km-rpm KDIR=/usr/src/kernels/`uname -r`/ # 启用内核模块 自动识别内核版本 # 返回： # You have now: # /root/rpmbuild/RPMS/x86_64/drbd-km-3.10.0_693.11.6.el7.x86_64-8.4.5-1.x86_64.rpm # /root/rpmbuild/RPMS/x86_64/drbd-km-debuginfo-8.4.5-1.x86_64.rpmmakeinsta 直接编译安装## drbd模块 cd drbd make make install lsmod|grep drbd cp drbd.ko /lib/modules/`uname -r`/kernel/lib/ ## 安装模块 modprobe drbd ## 验证drbd模块是否加载（部分系统默认有该模块） lsmod|grep drbd # drbd 364858 0 # libcrc32c 12644 4 xfs,drbd,nf_nat,nf_conntrack 编译drbd-utils组件cd ../../drbd-utils-8.9.0/ ./configure make rpm # 返回： ### + exit 0 You have now: /root/rpmbuild/RPMS/x86_64/drbd-km-3.10.0_693.11.6.el7.x86_64-8.4.5-1.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-km-debuginfo-8.4.5-1.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-8.9.0-1.el7.centos.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-utils-8.9.0-1.el7.centos.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-xen-8.9.0-1.el7.centos.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-udev-8.9.0-1.el7.centos.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-pacemaker-8.9.0-1.el7.centos.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-bash-completion-8.9.0-1.el7.centos.x86_64.rpm /root/rpmbuild/RPMS/x86_64/drbd-debuginfo-8.9.0-1.el7.centos.x86_64.rpm ### 此时有可能提示错误如下： /usr/bin/xsltproc \ --xinclude \ http://docbook.sourceforge.net/release/xsl/current/manpages/docbook.xsl drbdsetup.xml error : Operation in progress warning: failed to load external entity &quot;http://docbook.sourceforge.net/release/xsl/current/manpages/docbook.xsl&quot; cannot parse http://docbook.sourceforge.net/release/xsl/current/manpages/docbook.xsl make[1]: *** [drbdsetup.8] Error 4 提示有一个地址文件没能找到，解决方法： yum -y install docbook-style-xsl TODO: 此处暂未找到别的解决方法，欢迎读者留言。 安装安装编译生成的文件cd /root/rpmbuild/RPMS/x86_64/ rpm -ivh drbd-* --force 加载模块（参见分割线部分）modprobe drbd 验证安装结果lsmod|grep drbd # 返回（`depends` 可能略有不同）： # drbd 373375 4 # libcrc32c 12644 2 xfs,drbd drbd-overview # 以下两者返回稍有不同 cat /proc/drbd drbdadm -V # 返回 DRBDADM_BUILDTAG=GIT-hash:\ 79677f4***7ca6b99929\ build\ by\ root@imoyao\,\ 2018-01-06\ 14:25:03 DRBDADM_API_VERSION=1 DRBD_KERNEL_VERSION_CODE=0x080405 DRBDADM_VERSION_CODE=0x080900 DRBDADM_VERSION=8.9.0 参考来源 CentOS 7 : DRBD : Install : Server World CentOS 安装配置 DRBD – WTF Daily Blog CentOS下实现Heartbeat+DRBD+MySQL双机热备硬件故障自动切换高可用(HA)方案 | 三木的人生——3mu.me]]></content>
      <categories>
        <category>教程记录</category>
      </categories>
      <tags>
        <tag>DRBD</tag>
        <tag>Linux</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[🐍PyTricks | Python技巧写法记录]]></title>
    <url>%2Fblog%2F2018-01-02%2Fpytricks-collection%2F</url>
    <content type="text"><![CDATA[写出Pythonic的代码应该是每个Pythonista的基本追求，本文主要记录在开发中遇到的一些有关Python技巧。 排序 JSON字典内按照某个键值排序 In [15]: alist = [{&#39;create&#39;: &#39;2017-12-28 11:05:48&#39;, &#39;id&#39;: &#39;0_1&#39;, &#39;path&#39;: &#39;foo.py&#39;, &#39;size&#39;: 0}, ....: {&#39;create&#39;: &#39;2017-12-28 11:00:29&#39;, &#39;id&#39;: &#39;0_2&#39;, &#39;path&#39;: &#39;bar.py&#39;, &#39;size&#39;: 0}, ....: {&#39;create&#39;: &#39;2017-12-28 11:05:55&#39;, &#39;id&#39;: &#39;0_3&#39;, &#39;path&#39;: &#39;baz.py&#39;, &#39;size&#39;: 0}] In [16]: alist.sort(key=lambda x:x[&#39;create&#39;]) # 按照创建时间排序 In [17]: alist Out[17]:`` [{&#39;create&#39;: &#39;2017-12-28 11:00:29&#39;, &#39;id&#39;: &#39;0_2&#39;, &#39;path&#39;: &#39;bar.py&#39;, &#39;size&#39;: 0}, {&#39;create&#39;: &#39;2017-12-28 11:05:48&#39;, &#39;id&#39;: &#39;0_1&#39;, &#39;path&#39;: &#39;foo.py&#39;, &#39;size&#39;: 0}, {&#39;create&#39;: &#39;2017-12-28 11:05:55&#39;, &#39;id&#39;: &#39;0_3&#39;, &#39;path&#39;: &#39;baz.py&#39;, &#39;size&#39;: 0}] 字典排序 In [35]: languages = {&#39;JAVA&#39;:15,&#39;Python&#39;:12,&#39;Go&#39;:13,&#39;PHP&#39;:14} In [35]: sorted(languages.items(),key=lambda x:x[0]) # 以key排序 Out[35]: [(&#39;Go&#39;, 13), (&#39;JAVA&#39;, 15), (&#39;PHP&#39;, 12), (&#39;Python&#39;, 12)] In [36]: sorted(languages.items(),key=lambda x:x[1]) # 以value排序 Out[36]: [(&#39;Python&#39;, 12), (&#39;PHP&#39;, 12), (&#39;Go&#39;, 13), (&#39;JAVA&#39;, 15)] In [37]: sorted(languages.items(),key=lambda x:-x[1]) # 以value倒序 Out[37]: [(&#39;JAVA&#39;, 15), (&#39;Go&#39;, 13), (&#39;Python&#39;, 12), (&#39;PHP&#39;, 12)] 注意：sort()与sorted()的区别，前者返回值为None，后者可重新赋值； 参考阅读 PEP 8 – Style Guide for Python Code | Python.org Python 风格指南 — Google 开源项目风格指南]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年过去了，我很怀念它]]></title>
    <url>%2Fblog%2F2017-12-28%2FAnnual-record-of-2017%2F</url>
    <content type="text"><![CDATA[马上毕业三年，从前途迷茫,自我否定到逐渐看到一点努力的方向，给自己做一个简单的记录还是必要的。 年初，入职一家北大数学系某研究生创办的农业科技公司。第一次看到所谓的创业公司拿着高校办公计算机当作自己办公用品使用，也是第一次看见凌晨两点钟的北京。也曾梦想跟着自带光芒的人干一番大事业，却不料在短暂的时间之后就被干掉。抛开女老板不懂技术、没技术大牛带、技术团队就一草台班子，归根结底还得怪自己手艺不精。所以过年回家那段时间一直挺失落的，整个人可以说是相当「愁云惨淡万里凝」了。幸好还有高中的女同学Y的暖心安慰，才不至于对生活失去信心。回忆过往，内心泪流满面的同时对朋友们的鼓励表示默默感谢。 过年来还算顺利，在经过漫长而短暂的差不多半个月面试之后终于进入现在的公司。对于一个没有工作的人，可以说每一天都很煎熬，而且面试中带来的挫败感会逐渐让人对自己丧失信心。庆幸的是，柳暗花明之后，终于收到三份Offer，本着向钱看齐的指导方针选择了现在的公司。虽然谈不上多好，但是快饿死的人是没有资格挑食的，最重要还是先养活自己。 回顾在新公司的近一年时间，从开始的什么两眼一抹黑到现在可以实现新增功能的独立完成，难免唏嘘。当然，也暴露出自己在技术方面的欠缺：前端JavaScript有时需要同事帮助才可以搞定，对Python中的系统编程了解不够深入，目前陷入一种困难的搞不定，简单的又不屑做的尴尬境地。只能送自己一句革命仍未成功，同志仍需努力。 了解一个人最快的方式是：和一个男性发生金钱关系，和一个女性发生肉体关系。异性间的肉体关系我多半是近期不及见了，倒是可以聊聊今年和别人之间钱的问题。大概是6月的时候，某大学同学联系我说和室友合租住不下去了，问我是否能够凑合一下，租金均摊。虽然我习惯独居，但是考虑应该不会太久也就同意了。后来住到一块才知道是因为他晚上整宿磨牙被室友赶出来了。住了不到两个月他找到房子说要搬走，房钱大概算了 1000 多点，结果给我来了句「能不能抹个零，就当请我抽包烟？」我也就脸上笑嘻嘻，心里MMP地拒绝了他。刚好他那时才找到工作，于是又说宽限他十多天，月初发工资就还我。到了月初，我以为是忘了，10 号左右要的时候说花光了，下个月吧。下个月再要，又说什么爷爷去世，钱都用来料理后事了，事情处理完回去想办法。到了月底，我也没等到其想到的办法。说实话这么催的确太难看了点，但是一个月薪 13K 的欠别人 1.3K 还要拖那么久，最后到了 10 月发工资才给我。我的内心只能响起梁朝伟的那句「明明说好三年，三年之后又三年，三年之后又三年，都快十年了老大！」当然这还不是最奇葩的，最奇葩的是还钱之后，居然不联系我了。我想，大抵是因为我连 1000 块钱都要得罪人家了吧？毕竟，人家可能从来没想着住同学租的房子还要给钱。其实，我想问一句「哎，搬家时说好京东下单之后就还我的鼠标用坏了没呀？」 再一个就是今年父母开始时不时暗示该找个女朋友了，家人的关心也不无道理，没有组织关心的人是得提前考虑自己的个人问题。难堪的是虽然我本人自觉女生缘不错，但是可能女人缘实在是差了点，自从14年和前女友分手之后，至今还属于漫长的空窗期。而在这个狼多肉少的时代，项目组中的能够激发两性情感的妹子们都早早地被别人捷足先登了。从个人层面来说倒也不是着急，但是作为一个非「不婚族」个体，这个问题或许是得认真考虑一下啦。 还有最近有件比较困扰我的事，因为我极度不喜欢运动，所以一年来体重极速飙升，这真是一件残酷而危险的事情，希望能够克服困难，通过节食加锻炼控制在可接受的范围之内。 身处大时代，每个人都是有各种无奈。裹挟在西二旗早高峰人流中意气风发的少年被岁月早早地盘出了油腻的包浆；回不去的家乡和触不到的梦想如烧红的铁板的反覆煎熬着身心；高不可攀的房价和日益年迈的父母也开始往人的肩膀上增添重量感。人生的路呵，怎么越走越窄…… 当然，平心而论觉得自己还是很幸运的。在父母的经济支持下来到这边站住脚，起码到北京之后的日子里，结余多过之前的工资，而且也不再像之前做没有技术含量的卑微活计。对这份工作谈不上热爱，也没有改变世界的勇气和能力，目前只希望尽力做好本职工作吧。 繁华世界，不敢爱慕，不敢憧憬，不知不觉在开心时也小心翼翼。意犹未尽，见好就收。 絮絮叨叨写了这么些，发现也没啥重点可以突出一下，看来遣词造句能力退化不少。行吧，让我满斟烈酒：一杯敬明天，一杯敬过往。给所有像我这样的人。 像我这样优秀的人本该灿烂过一生怎么二十多年到头来还在人海里浮沉 像我这样聪明的人早就告别了单纯怎么还是用了一段情去换一身伤痕 像我这样迷茫的人像我这样寻找的人像我这样碌碌无为的人你还见过多少人像我这样庸俗的人 像我这样懦弱的人凡事都要留几分怎么曾经也会为了谁想过奋不顾身 你还见过多少人像我这样孤单的人像我这样傻的人像我这样不甘平凡的人像我这样莫名其妙的人 以上文字引用略有删改]]></content>
      <categories>
        <category>个人日记</category>
      </categories>
      <tags>
        <tag>Diary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storcli常用管理命令汇总]]></title>
    <url>%2Fblog%2F2017-12-27%2Fstorcli-command-share%2F</url>
    <content type="text"><![CDATA[目前LSI RAID卡使用的配置工具主要有：Megaraid Storage Manager（MSM，图形环境）、MegaCLI（字符界面）、StorCLI（字符界面）。其中StorCLI作为MegaCLI后继者整合了LSI和原来3ware的产品支持，兼容MegaCLI命令的同时更加简洁。前面的文章记录了MegaCli常用管理命令，本篇主要记录StorCLI的使用。 安装StorcliUbuntu:unzip ul_avago_storcli_1.18.11_anyos.zip dpkg -i storcli_all_os/Ubuntu/storcli_1.18.11_all.deb dpkg -l | grep -i storcli Centos:unzip ul_avago_storcli_1.18.11_anyos.zip rpm -ivh storcli_all_os/Linux/storcli-1.18.11-1.noarch.rpm rpm -qi storcli ln -s /opt/MegaRAID/storcli/storcli64 /usr/local/bin/storcli ESXi 5.5 &amp; ESXi 6.0:unzip ul_avago_storcli_1.18.11_anyos.zip esxcli software vib install -v=vmware-esx-storcli-1.21.06.vib --no-sig-check ln -s /opt/lsi/storcli/storcli /sbin/storcli storcli -V storcli使用专有名词解释： /cx, /vx 表示 Controller/Virtual Drive Number. /ex, /sx表示 Enclosure/Slot ID. VD表示 Virtual Drive. 要输出json格式的返回,在命令行最后添加J. 固件升级 storcli /cx download file=/path/to/firmware.rom 查看控制器和配置信息 storcli /cx show all 使用激活码激活特性(如 CacheCade, FastPath,…) storcli /cx set aso key=AAAAAAAABBBBBBBBCCCCCCCC 查看现有硬盘及其状态的信息 (IDs,…) storcli /cx /eall /sall show (all) 返回结果 Controller = 0 Status = Success Description = Show Drive Information Succeeded. Drive Information : ================= ----------------------------------------------------------------------------- EID:Slt DID State DG Size Intf Med SED PI SeSz Model Sp ----------------------------------------------------------------------------- 252:0 1 Onln 1 3.637 TB SATA HDD N N 512B WDC WD4000FYYZ-03UL1B3 U 252:1 3 Onln 1 3.637 TB SATA HDD N N 512B WDC WD4000FYYZ-03UL1B3 U ...... 252:6 85 Onln 0 3.637 TB SATA HDD N N 512B WDC WD4000FYYZ-03UL1B3 U 252:7 2 UGood - 3.637 TB SATA HDD N N 512B WDC WD4000FYYZ-03UL1B3 D ----------------------------------------------------------------------------- EID-Enclosure Device ID|Slt-Slot No.|DID-Device ID|DG-DriveGroup DHS-Dedicated Hot Spare|UGood-Unconfigured Good|GHS-Global Hotspare UBad-Unconfigured Bad|Onln-Online|Offln-Offline|Intf-Interface Med-Media Type|SED-Self Encryptive Drive|PI-Protection Info SeSz-Sector Size|Sp-Spun|U-Up|D-Down|T-Transition|F-Foreign UGUnsp-Unsupported|UGShld-UnConfigured shielded|HSPShld-Hotspare shielded CFShld-Configured shielded|Cpybck-CopyBack|CBShld-Copyback Shielded 现有虚拟硬盘及其状态的信息 storcli /cx /vall show (all) 查看当前所有重建的状态 storcli /cx /eall /sall show rebuild 创建/初始化 raid shell创建VD storcli /cx add vd type=[RAID0(r0)|RAID1(r1)|...] drives=[EnclosureID:SlotID|:SlotID-SlotID|:SlotID,SlotID] #more storcli /cx add vd type=raid[0|1|5|6|00|10|50|60(r0|r1|...)] [Size=&lt;VD1_Sz&gt;,&lt;VD2_Sz&gt;,..|all] [name=&lt;VDNAME1&gt;,..] drives=e:s|e:s-x,y;e:s-x,y,z [PDperArray=x] [SED] [pdcache=on|off|default] [pi] [DimmerSwitch(ds)=default|automatic(auto)|none|maximum(max)|MaximumWithoutCaching(maxnocache)] [wt|wb] [nora|ra] [direct|cached] [CachedBadBBU|NoCachedBadBBU][cachevd] [Strip=&lt;8|16|32|64|128|256|1024&gt;] [AfterVd=X] [Spares = [e:]s|[e:]s-x|[e:]s-x,y] [force][ExclusiveAccess] 示例: # 使用硬盘0-2创建raid1 storcli /cx add vd type=r1 drives=252:0-2 # 创建 raid5,write-bakc,read-ahead storcli /cx add vd type=raid5 size=all names=VD1 drives=32:2-7 wb ra # 创建 raid10/50/60,必须设定PDperArray参数,write-bakc,read-ahead storcli /cx add vd type=raid10 size=all names=VD1 drives=32:2-7 PDperArray=2 wb ra shell之初始化VD storcli /cx/vx start init (force) 监视初始化进度 storcli /cx/vx show init shell之移除VD storcli /cx/vx del (force) 缓存加速 shell之创建CacheCade设备（SSD缓存加速） storcli /cx add vd cc type=r[0,1,10] drives=[EnclosureID:SlotID|:SlotID-SlotID|:SlotID,SlotID] WT|WB (assignvds=0,1,2) 示例: storcli /c0 add vd cc type=r1 drives=252:2-3 WB shell之CacheCade激活/停用 storcli /cx/[vx|vall] set ssdCaching=[on|off] 示例: storcli /c0/v1 set ssdCaching=on shell之移除CacheCade storcli /cx/vx del cc 误插拔设备合并如果不正确地移除设备并重新连接到RAID控制器，它将被识别为UBAD(Unconfigured Bad)。 storcli /c0 /eall /sall show 此时的返回结果： Controller = 0 Status = Success Description = Show Drive Information Succeeded. Drive Information : ================= ------------------------------------------------------------------------------- EID:Slt DID State DG Size Intf Med SED PI SeSz Model Sp ------------------------------------------------------------------------------- 252:0 7 Onln 0 465.25 GB SATA HDD N N 512B WDC WD5003ABYX-01WERA1 U 252:1 6 Onln 1 465.25 GB SATA HDD N N 512B WDC WD5003ABYX-01WERA1 U 252:2 5 UGood - 465.25 GB SATA HDD N N 512B WDC WD5003ABYX-01WERA1 U 252:3 4 UBad - 223.062 GB SATA SSD N N 512B INTEL SSDSC2CW240A3 U ------------------------------------------------------------------------------- ...... 此时252:3必需置为UGOOD UBad置为UGOOD storcli /cx /ex /sx set good 返回结果 Controller = 0 Status = Success Description = Show Drive Information Succeeded. Drive Information : ================= ------------------------------------------------------------------------------- EID:Slt DID State DG Size Intf Med SED PI SeSz Model Sp ------------------------------------------------------------------------------- 252:0 7 Onln 0 465.25 GB SATA HDD N N 512B WDC WD5003ABYX-01WERA1 U 252:1 6 Onln 1 465.25 GB SATA HDD N N 512B WDC WD5003ABYX-01WERA1 U 252:2 5 UGood - 465.25 GB SATA HDD N N 512B WDC WD5003ABYX-01WERA1 U 252:3 4 UGood F 223.062 GB SATA SSD N N 512B INTEL SSDSC2CW240A3 U ------------------------------------------------------------------------------- foreign管理 此时硬盘为foreign状态 storcli /cx /fall show 返回结果 Controller = 0 Status = Success Description = Operation on foreign configuration Succeeded FOREIGN CONFIGURATION : ===================== ---------------------------------------- DG EID:Slot Type State Size NoVDs ---------------------------------------- 0 - Cac0 Frgn 223.062 GB 1 ---------------------------------------- NoVDs - Number of VDs in disk group|DG - Diskgroup Total foreign drive groups = 1 现在它可以重新包含在配置中 storcli /cx /fall import 如果设备是RAID的一部分，则会自动执行重建（请参阅概述中的状态：Rbld）。 可用以下命令监视进度： storcli /cx /ex /sx show rebuild 其他# 查看VD健康状态等,获取到坏盘的E:S编号,然后查看对应盘的SN storcli /c0 /vall show [all] storcli /c0 /eX /sY show all |grep SN # 查看阵列卡 storcli show ctrlcount # 查看 virtual disk 0 @controlor 0 storcli /cx /v0 show # 查看 Controlor-0, Enclosure-7, Slot-7的磁盘信息 storcli /cx/e252/s7 show all # 查看报警信息 storcli /cx show alarm # 关闭beep蜂鸣器报警 storcli /cx set alarm=&lt;on|off|silence&gt; # 定位磁盘仓位 storcli /c0/e8/s2 start/stop locate 参考来源 官方相关资源下载-broadcom StorCLI官方手册下载 StorCLI _Thomas-Krenn STORCLI-wiki（个人博主维护）]]></content>
      <categories>
        <category>教程记录</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>Linux</tag>
        <tag>RAID</tag>
        <tag>Storcli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python资源推荐--[书籍篇]]]></title>
    <url>%2Fblog%2F2017-12-03%2Frecommend-books-for-Python-learner%2F</url>
    <content type="text"><![CDATA[因为我目前做Python相关开发，很多想入门Python的朋友或者从事其他语言开发的同学私聊讨论书籍资料推荐的话题，其实网上有很多关于这个问题的话题总结，我个人的推荐并不见得比大神更好，希望真正想沉下心来学习的人能够早点明白“自己动手，丰衣足食”的道理。在这里做个简单整理也算是给大家一个交代，以不留下盛气凌人的傲慢印象为盼。 红药丸还是蓝药丸？刚开始学习编程的时候，很多人会有各种困惑：选择哪门语言？选择语言的哪个版本？用什么编辑器/开发平台…… 相信看这篇文章的对第一个问题已然有了自己的选择，在此不多赘述。关于Python版本的问题，时至今日（2017年），除非公司项目需要，不然请果断选择Python3，毕竟大多数第三方库已经做出放弃Python2维护的相关说明。第三个问题倒是不用过分纠结，毕竟只要能够run，哪怕是用记事本写的也没人会在意。个人目前使用Sublime Text 3搭配IDE PyCharm。 入门篇 《”笨办法”学 Python》 （《Learn Python the Hard Way》） 笨办法学 Python -Gitbook 学习一门语言的最好办法就是多敲多用，妄图靠眼睛看会一门技术的人，希望能够早点丢掉幻想，准备战斗！ 这本简单书的目的是让你起步编程。 虽然书名说是“笨办法”,但其实并非如此. 所谓的“笨办法”是指本书教授的方式。这本书的教学方式就是按照我告诉你的方式去做一系列的练习，目的是通过重复练习掌握一种技能。这对于一些什么都不知道的初学者，在理解更复杂的科目之前获取基本能力是很有效的方法。这种方法适用于一切领域，从武术到音乐甚至基本的数学和阅读技巧。这本书以习题的方式引导读者一步一步学习编程，从简单的打印一直讲到完整项目的实现。也许读完这本书并不意味着你已经学会了编程，但至少你会对编程语言以及编程这个行业有一个初步的了解。 《简明 Python 教程》 （《A Byte of Python》） 简明 Python 教程-Gitbook 看一下激动人心的前言介绍： 本书将以指南或教程的形式向你介绍Python这门编程语言。它以新手为主要目标。同时本书也对有经验的程序员有所帮助。如果你对电脑的所有了解仅止步于如何保存文本文件的话，那本书的目标便是协助你通过本书学习Python。如果在此之前你已经有了编程经验，你同样可以通过本书来学习Python。如果你已经有过编程经验，你或许会对Python与其它你所喜爱的编程语言间有何区别抱有兴趣——而我将会你展现许多这种区别。顺便提醒你一下，Python将会很快成为你最喜欢的编程语言！ 《 Python 3.3 官方教程》 Python 入门指南中文版 Python 官方教程（英文原版） 更新、权威、条理化的官方tutorial ，最原汁原味的Python指南。 《零基础学 Python》/《跟老齐学 Python》 零基础学Python 这本教程是我当初开始自学的时候看过的，由于是国内作者，语言习惯更适合我们，顺便也推荐给大家。 在我看来，Python是非常适合作为学习高级语言编程的第一门语言的。有一本书，名字叫《与孩子一起学编程》，这本书的定位，是将python定位为学习者学习的第一门高级编程语言。然而，由于读者对象是孩子，很多“成年人”不屑一顾，当然，里面的讲法与“实战”有点距离，导致以“找工作”、“工作需要”为目标的学习者，认为这本书跟自己要学的方向相差甚远。为了弥补那本书的缺憾，我在这里推出面向成年人——大学生、或者其他想学习程序但是没有任何编程基础的朋友——学习第一门编程高级语言的教程。 读完上面的书，你已经掌握Python的语法特点，可以看懂语言逻辑，也可以按照自己的想法写一点小demo了。这个时候，如果打算从事相关工作，可以尝试迈出第一步啦。需要提醒大家的是：读书和做写代码应该是并驾齐驱的，不能一味地去读书，也不要一味敲代码。（当然，你可能也写不出来）只有相互有机结合，才能记得稳固，学得牢靠。 进阶篇 《流畅的 Python》 (《Fluent Python-Clear, Concise, and Effective Programming》) 流畅的 Python(未完成) 这本书并不是一本完备的 Python 使用手册，而是会强调 Python 作为编程语言独有的特性，这些特性或者是只有 Python 才具备的，或者是在其他大众语言里很少见的。本书的目标读者是那些正在使用 Python，又想熟悉 Python 3 的程序员。本书的主要目的是为了充分地展现 Python 3.4 的魅力。 《《Python Cookbook》3rd Edition 》 Python Cookbook 这本书的目标读者是那些想深入理解Python语言机制和现代编程风格的有经验的Python程序员。本书大部分内容集中于在标准库，框架和应用程序中广泛使用的高级技术。本书所有示例均假设读者具有一定的编程背景并且可以读懂相关主题 （比如基本的计算机科学知识，数据结构知识，算法复杂度，系统编程，并行，C 语言编程等）。 另外，每个示例都只是一个入门指导，如果读者想深入研究，需要自己去查阅更多资料。我们假定读者可以很熟练的使用搜索引擎以及知道怎样查询在线的Python文档。 读完上面的书，你已经可以写出Pythonic的代码了，应该对Python有了自己的理解，并且也会有自己的方向，可以确定自己的发展方向：Web应用开发、爬虫数据分析、网络安全、运维测试、Linux系统开发、人工智能/机器学习。相信这个时候你已经不再需要别人的推荐，那么是时候为Python的蓬勃发展贡献自己的力量啦！ More免费中文Python电子书（教程）Awesome Python Books]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python进行计数统计]]></title>
    <url>%2Fblog%2F2017-11-21%2Fhowto-count-sequense-with-python%2F</url>
    <content type="text"><![CDATA[from collections import Counter 使用常规for循环 In [53]: test_seq = &#39;asfsdgfads&#39; In [54]: count_dict = dict() In [55]: for item in test_seq: ...: if item in count_dict: ...: count_dict[item] += 1 ...: else: ...: count_dict[item] = 0 ...: In [56]: count_dict Out[56]: {&#39;a&#39;: 1, &#39;d&#39;: 1, &#39;f&#39;: 1, &#39;g&#39;: 0, &#39;s&#39;: 2} 使用collections库中的defaultdictIn [57]: from collections import defaultdict In [58]: cd_dict = defaultdict() In [59]: cd_dict = defaultdict(int) In [60]: for item in test_seq: ...: cd_dict[item] += 1 ...: In [62]: cd_dict Out[62]: defaultdict(int, {&#39;a&#39;: 2, &#39;d&#39;: 2, &#39;f&#39;: 2, &#39;g&#39;: 1, &#39;s&#39;: 3}) In [63]: cd_dict.items() Out[63]: [(&#39;a&#39;, 2), (&#39;s&#39;, 3), (&#39;d&#39;, 2), (&#39;g&#39;, 1), (&#39;f&#39;, 2)] 使用collections库中的CounterIn [64]: from collections import Counter In [65]: Counter(test_data) Out[65]: Counter({&#39;a&#39;: 1, &#39;d&#39;: 3, &#39;g&#39;: 3, &#39;h&#39;: 1, &#39;s&#39;: 2}) In [84]: counter = Counter(test_seq) In [85]: counter.items() Out[85]: [(&#39;a&#39;, 2), (&#39;s&#39;, 3), (&#39;d&#39;, 2), (&#39;g&#39;, 1), (&#39;f&#39;, 2)] 参考书籍 《编写高质量代码：改善Python程序的91个建议》迷你书-建议 39：使用 Counter 进行计数统计]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>HOWTO</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘阵列控制卡（RAID卡）MegaCli常用管理命令汇总]]></title>
    <url>%2Fblog%2F2017-11-20%2Fmegacli-command-share%2F</url>
    <content type="text"><![CDATA[进行存储开发时需要创建磁盘阵列，本文主要记录 RAID 卡管理工具MegaCli的使用。需要注意的是，目前该管理工具因为商业收购已经被官方“弃坑”，StorCLI作为后继者整合了LSI和原来3ware的产品支持，兼容MegaCLI命令的同时更加简洁，参阅此篇。 巡读#立即激活 MegaCli -adppr -enblauto -a0 #设置成手动模式，需要用MegaCli -adppr -start –a0 来激活 MegaCli -adppr -enblman -a0 #查看巡读的模式，本次巡读结束与下一次开始巡读的间隔，当前状态等信息 MegaCli -adppr -info -a0 #查看巡读的进度 MegaCli -fwtermlog -dsply -a0 #结束巡读，在巡读过程中，多次运用MegaCli -adppr -stop -a0或MegaCli -adppr -start -a0会使叠代数增加，此时可能不能开始或结束巡读，用MegaCli -adppr -dsbl -a0来禁止巡读，重新开始。 MegaCli -adppr -stop -a0 #设置本次巡读结束与下一次巡读开始的时间间隔，默认是168小时，当val=0时, 本次巡读结束后，立即开始下一次巡读 MegaCli -adppr -setdelay val -a0 #巡读时是否纠正媒介错误 MegaCli -AdpSetProp -PrCorrectUncfgdAreas -val -a0 #设置定时巡读 yyyymmdd hh，具体含义如下：20120108 16表示2012年01月08日16点 MegaCli -AdpPR -SetStartTime yyyymmdd hh -a0 cc校验 立即开始cc校验 #L0表示Target ID 为0的raid组 MegaCli -ldcc -start -L0 –a0 #如果没有完全初始化或后台初始化 #The virtual disk has not been initialized、 Running a consistency check may result in inconsistent messages in the log #可以强行cc校验 MegaCli -ldcc -start -force –L0 –a0 #显示当前cc校验的进度 MegaCli -ldcc -progdsply -L0 -a0 #关掉当前的cc校验 MegaCli -ldcc -abort -L0 -a0 计划cc校验如果模式为disable(MegaCli -adpccsched -info -a0来查看)，则下一次开始时间为07/28/2135, 02:00:00，状态为 Stopped，延期为168个小时;只有模式为Sequential和Concurrent模式时，才可以设定定期时间，所以要首先设定模式;如果模式为Sequential时，所有虚拟磁盘组顺序进行cc校验;如果模式为Concurrent时，所有虚拟磁盘组同时进行cc校验;#设定CC模式 MegaCli -adpccsched -modeconc -a0 #或者 MegaCli -adpccsched -modeseq -a0 #然后设定开始时间 MegaCli -adpccsched setstarttime 20101122 18 -a0 #设置本次cc校验结束和下次cc校验开始的时间间隔 MegaCli -adpccsched -setdelay 2 -a0 #禁止计划cc校验 MegaCli -AdpCcSched -dsbl -a0 #设置错误发生时放弃cc校验 MegaCli -adpsetprop -AbortCC -1 -a0 #查看cc校验的事件日志 MegaCli -AdpEventLog -GetCCIncon –f filename –L0 –a0 #如果设置延期时间为0，本次cc校验结束后，下一次cc校验会立即开始 快速初始化和完全初始化快速初始化值是往raid组的前8M和后8M写0 #快速初始化 MegaCli -LDInit -start –L0 -a0 #完全初始化 MegaCli -LDInit -start -full –L0 -a0 #显示初始化的进度 MegaCli -LDInit -progdsply -L0 -a0 #结束完全初始化 MegaCli -LDInit -abort -L0 -a0 后台初始化Raid5 需要5个数据盘才可以后台初始化(5个盘中不包含热备盘)后台初始化是创建raid后5分钟开始的(好像有时不是这样的)后台初始化和cc校验不同的地方是，后台初始化可以自动开始改变后台初始化率时，需要停止后台初始化，否则没有效果 #禁止后台初始化 MegaCli -LDBI -dsbl -L0 -a0 #结束正在进行的后台初始化 MegaCli -LDBI -abort -L0 -a0 #查看后台初始化的设置 MegaCli -LDBI -getsetting -L0 -a0 #显示后台初始化进度 MegaCli -LDBI -progdsply -L0 -a0 copyback#开启或禁用copyback MegaCli -AdpSetProp –CopyBackDsbl -0 -a0 (开启) #显示copyback设置情况 MegaCli –AdpGetProp -CopyBackDsbl –a0 当设置copyback为enable时，拔出坏盘，换上一个UNCONF的新盘，先用热备盘进行重建，然后进行copyback操作，如果copyback为disable时，不进行copyback操作，可以设定copyback为enable，然后用MegaCli -PDCpyBk -Start -PhysDrv[E0:S0,E1:S1] –a0开始copyback操作，其中[E0：S0]是raid组中的磁盘(源盘)，而[E1：S1]不是raid组中的磁盘(目的盘) 当某个盘出现第一个smart错误时，可以在这个盘和热备盘之间进行copyback操作，热备盘作为目的盘，完成了copyback操作时，smart错误盘才标记为failed状态。 #如果在copyback时，raid组删除，目的盘回到热备盘状态或Unconfigured Good MegaCli -AdpGetProp SMARTCpyBkEnbl -a0 日志#查看所有的information日志 MegaCli -adpalilog -a0 #查看固件调试日志(固件终端日志) MegaCli -fwtermlog -dsply -a0 #查看raid卡日志 MegaCli -adpeventlog -getevents -f filename -a0 #清除日志 MegaCli -AdpEventLog -Clear –a0 raid5扩容#raid5的扩容 MegaCli -LDRecon -Start -r5 -Add -Physdrv[E0:S0] -L0 -a0 #查看扩容的进度 MegaCli -LDRecon -progdsply -L0 –a0 级别迁移在迁移过程中，转换前的raid的一个盘下线，转换前raid的所有盘都下线 支持的类型 RAID 0 to RAID 1，RAID 0 to RAID 5，RAID 0 to RAID 6，RAID 1 to RAID 0，RAID 1 to RAID 5，RAID 1 to RAID 6，RAID 5 to RAID 0，RAID 5 to RAID 6，RAID 6 to RAID 0，RAID 6 to RAID 5 #建立了三个盘的raid 0 MegaCli -cfgldadd -r0[117:1,117:3,117:11] -a0 #增加一个盘[117:14],转换到raid5 MegaCli -ldrecon -start -r5 -add -physdrv[117:14] -l0 -a0 升级ROM#从低版本到高版本升级 MegaCli -adpfwflash -f x.rom -a0 #从高版本到低版本降级 #加上noverchk忽略版本的检查，升级以后需要重启才生效 MegaCli -adpfwflash -f x.rom -noverchk -a0 连接方式Raid对内有两个接口，即connector0和connector1。得到连接器的状态; MegaCli -adpgetconnectormode -connector0 -a0如果连接器的模式为internal时，jbod的磁盘全部看不到，如果连接器的模式为external时，主柜上的磁盘全部看不到; 外来配置#扫描外来配置的个数 MegaCli -cfgforeign -scan -a0 #查看当前的磁盘在normal时的位置 MegaCli -cfgforeign -preview -a0 #来导入配置，恢复虚拟磁盘组 MegaCli -cfgforeign -import -a0 #清除外来配置 MegaCli -cfgforeign -clear -a0 #显示出现外来配置(磁盘插入的顺序)的过程 MegaCli -cfgforeign -dsply -a0 物理磁盘的处理#磁盘的状态由FAULTY变成CONF MegaCli -PDMakeGood -PhysDrv[E0:S0] –a0 #磁盘上线 MegaCli -PDOnline -PhysDrv[E0:S0,E1:S1,...] –a0 #磁盘下线 #failed状态的盘可以下线，然后用MegaCli -pdmarkmissing -physdrv[E0:S0] -a0让磁盘踢盘，让其他的UNCONF状态的磁盘来替代这个盘MegaCli -PdReplaceMissing -physdrv[E0:S0] -arrayA, -rowB -a0 MegaCli -PDOffline -PhysDrv[E0:S0,E1:S1,...] –a0 #此时磁盘处于Spun down状态，如果用此磁盘来建立raid，则磁盘的状态自动变成Spun Up MegaCli -PdPrpRmv -physdrv[E0:S0] –a0 #清除单个磁盘 MegaCli -pdclear -start -physdrv[E:S] -a0 #设置热备盘的节电策略 MegaCli -AdpSetProp –DsblSpinDownHSP -val –a0 #设置空闲盘的节电策略 MegaCli -AdpSetProp –EnblSpinDownUnConfigDrvs -val –a0 #获取所有磁盘的详细信息 MegaCli -PDList –a0 #获取单个盘的详细信息 MegaCli -pdInfo -PhysDrv[E0:S0] –a0 Adpsetprop设置属性RebuildRate ，PatrolReadRate，BgiRate，CCRate，ReconRate，表示进行重建，巡读，后台初始化，cc校验，扩容等所占有的系统资源率，提高速度 CoercionMode(强制模式)，分成三种形式，None，128M，1G，当为1G时，每个磁盘比没有设置的时减少了1G的空间; PredFailPollInterval，轮询预测失败的时间间隔。Predictive Failure Count就是smart错误; MaintainPdFailHistoryEnbl 保存坏盘的历史记录。当为enable时，当一个盘掉线并重新上线。需要清除配置信息，添加为热备盘才可以重建当为disable时。当一个盘掉线并重新上线，自动重建; #设置Cluster模式，目前不支持，只能设置为disbale MegaCli -AdpSetProp ClusterEnable -0 -a0 #设置jbod模式，针对raid0有效，对单个盘读写，即先写第一个盘，写满了在写第二个盘。MegaCli -PDMakeJBOD -physdrv[E0:S0,E1:S1] -a0 可以设置jbod模式(目前不支持) MegaCli -AdpSetProp -EnableJBOD -1 -a0 #让设备驱动暴露enclosure devices MegaCli -AdpSetProp ExposeEnclDevicesEnbl -1 -a0 NCQNative Command Queuing (NCQ)对硬盘的读写命令的顺序进行优化。带NCQ技术的硬盘在接到读写指令后，会根据指令对访问地址进行重新排序。比如根据指令，硬盘需要访问330扇区、980扇区、340扇区，由于数据在磁盘上分布位置不同，普通硬盘只会按部就班地依次访问。而NCQ硬盘对指令进行优化排列之后，就可以先读取330扇区，接着读取340扇区，然后再读取980扇区。这样做的好处就是减少了磁头臂来回移动的时间，使数据读取更有效，同时有效地延长了硬盘的使用寿命。 #显示NCQ的设置情况 MegaCli -adpgetprop -NCQdsply -a0 #设置开启NCQ MegaCli -adpsetprop -NCQenbl -a0 #关闭NCQ MegaCli -adpsetprop -NCQdsbl -a0 添加和移除热备盘#添加局部热备盘，其中array0表示第0个raid MegaCli -PDHSP -Set -Dedicated -Array0 -physdrv[E:S] -a0 #添加全局热备盘 MegaCli -pdhsp -set -physdrv[E:S] -a0 #移除全局和热备局部热备 MegaCli -pdhsp -rmv -physdrv[E:S] -a0 重建#查看重建的进度 MegaCli -PDRbld -progdsply -physdrv[E:S] -a0 #调快重建的速度 MegaCli -AdpSetProp RebuildRate -val -a0 #设置自动重建，当一个盘坏掉时，热备盘可以自动重建，代替坏的盘 MegaCli -AdpAutoRbld -Enbl -a0 #手动开始重建，E0:S0表示坏的盘 MegaCli -PDRbld -Start -PhysDrv [E0:S0] -a0 恢复出厂设置#恢复出厂的默认配置 MegaCli -AdpFacDefSet –a0 告警#临时关闭，重启又变成开启 MegaCli -AdpSetProp -AlarmSilence –a0 #永久关闭，重启后还是关闭 MegaCli -AdpSetProp -AlarmDsbl –a0 #开启 MegaCli -AdpSetProp -Alarmenbl –a0 #查看告警的状态 MegaCli -AdpgetProp -Alarmdsply –a0 配置相关#可以查看一组磁盘上的多个raid的配置 MegaCli -CfgDsply -a0 #保存配置文件 MegaCli -CfgSave -f filename -a0 #导入配置文件，Raid组的配置文件放在最后，放在每个磁盘的最后512M，主要包含数据从哪里开始写的配置和用来Migration 的swap文件 MegaCli -CfgRestore -f filename -a0 #启动时恢复外来配置 MegaCli -AdpSetProp -AutoEnhancedImportEnbl -a0 #验证配置文件和文件的内容 MegaCli -AdpSetVerify -f fileName -a0 RAID卡相关#查看raid的配置信息 MegaCli -adpallinfo -a0 #关闭raid卡 MegaCli -adpShutDown -a0 #获取raid的时间 MegaCli -adpGetTime -a0 #对raid进行诊断 MegaCli -AdpDiag val -a0 #设置负载均衡，Raid卡对终端设备采用多路径访问，一半的设备通过一条路径，另一半的设备通过另一条路径，一条途径有盘插入和移除时，启动负载平衡，避免设备有重用 MegaCli -AdpSetProp –LoadBalanceMode -val –a0 #获取raid卡的个数 MegaCli –adpCount #获取pci信息 MegaCli -AdpGetPciInfo -a0 #Raid卡的在线重置，fw重置raid卡控制器芯片 MegaCli -AdpSetProp DisableOCR -val -a0 #显示raid卡，系统等的一些简单信息 MegaCli -ShowSummary -f filename -a0 #显示每个phy的错误数 MegaCli -PhyErrorCounters -a0 Enclosure的信息#查看机柜的相关信息 MegaCli -encinfo -a0 #查看机柜的状态 MegaCli -encstatus -a0 BIOS相关#在启动时要按任意键才可以启动这种情况设置这个参数。但是首先要确保 bios 处于 enable 状态。通过 MegaCli -AdpBIOS -dsply -a0可以查看。如果不是，先用MegaCli -AdpBIOS -enbl -a0来设置 MegaCli –AdpBIOS –BE –a0 #把当前的Raid组作为启动 MegaCli –AdpBootDrive -set -L0 -a0 背板相关#如果背板 disable 时，会自动的去检测背板 MegaCli -AdpSetProp -AutoDetectBackPlaneDsbl -val –a0 启动时上电#设置一次上电的磁盘的个数 MegaCli -AdpSetProp SpinupDriveCount -val -a0 #设置上电的延迟时间 MegaCli -AdpSetProp SpinupDelay -val -a0 刷新缓存#刷新raid卡缓存 MegaCli -AdpCacheFlush –a0 #刷缓存的时间间隔 MegaCli -AdpSetProp CacheFlushInterval –val –a0 让硬盘LED灯闪烁#开启blink MegaCli -AdpSetProp UseDiskActivityforLocate -1 -a0 #让硬盘LED灯闪烁 MegaCli -PdLocate -start –physdrv[E:S] -a0 #停掉硬盘LED灯 MegaCli -PdLocate -stopt –physdrv[E:S] -a0 电池告警MegaCli -AdpSetProp BatWarnDsbl -val -a0 纠错码相关#设置纠错码漏桶的字节数 MegaCli -AdpSetProp EccBucketSize -val -a0 后台初始化，完全初始化，cc校验，巡读等之间的关系后台初始化和完全初始化，cc校验时不能进行巡读;巡读时可以后台初始化和完全初始化，此时巡读结束;;在后台初始化和cc校验时，不能开始完全初始化;扩容时不能建raid，不能添加热备盘;rebuild的优先级高于copyback; RAID 的创建与删除 创建raid 0，1，5，6 #MegaCli -CfgLdAdd -rX[E0:S0,E1:S1,...] [WT|WB] [NORA|RA|ADRA] [Direct|Cached] [CachedBadBBU|NoCachedBadBBU] [-szXXX [-szYYY ...]] [-strpszM] [-Hsp[E0:S0,...]] [-AfterLdX] [-Force]|[FDE|CtrlBased] -a0 可以设置写模式(wt，wb)，读模式(ra，nora，adra)，缓存模式(direct，cached)，大小(sz)，条块大小(strpszM)等。比如1000G，只用指定盘的一部分(sz1000G)，设置条块的大小strpsz(设置为16k，则为strpsz16) MegaCli -cfgldadd -r5[117:1,117:3,117:11] -wb -ra -cached -cachedbadbbu -force -a0 创建raid 10，50，60 #MegaCli -CfgSpanAdd -rX-Array0[E0:S0,E1:S1] -Array1[E0:S0,E1:S1] [-ArrayX[E0:S0,E1:S1] ...] [WT|WB] [NORA|RA|ADRA] [Direct|Cached] [CachedBadBBU| NoCachedBadBBU] [-szXXX[-szYYY ...]][-strpszM][-AfterLdX][-Force] |[FDE|CtrlBased] -aN MegaCli -CfgSpanAdd -r10 -Array0[245:0,245:1] Array1[245:2,245:3] -WB -RA -Cached -Cachedbadbbu -a0 批量创建raid0 #把每个槽位的磁盘都创建为只有一个盘的raid0 MegaCli -CfgEachDskRaid0 -wb -ra -cached -cachedbadbbu -a0 #把所有的空闲盘都加入到raid中 MegaCli -CfgAllFreeDrv -r5 -SATAOnly -wb -ra -cached -cachedbadbbu -a0 删除raid组 #清除所有的raid组的配置 MegaCli -cfgclr -a0 #删除指定的raid组(Target Id: 0)的raid组 MegaCli -cfglddel -L0 -a0 设置RAID组的属性#设置raid组的名字 MegaCli -ldsetprop -name dg -L0 -a0 #设置访问策略为读写，MegaCli -ldsetprop -blocked -L0 -a0设置访问策略为阻塞，此时raid组的设备不可以访问，fdisk -l不能发现设备 MegaCli -ldsetprop -rw -L0 -a0 #设置写策略为wt(直写)，直接写入到硬盘上，然后再返回。wb模式是写入到缓存中就返回，设置wb模式写速度有显著的改善，提高到12倍 MegaCli -ldsetprop -wt -L0 -a0 #设置读策略为ra(预先读出一定的数据)，还有nora模式，ra模式读可以提高到2倍左右 MegaCli -ldsetprop -ra -L0 -a0 #设置缓存策略为cached MegaCli -ldsetprop -cached -L0 -a0 #开启磁盘的缓存，对写速度有一定的提高(1.4倍) MegaCli -ldsetprop -endskcache -L0 -a0 查询篇 显示BBU状态信息 MegaCli -AdpBbuCmd -GetBbuStatus –aALL 显示BBU容量信息 MegaCli -AdpBbuCmd -GetBbuCapacityInfo –aALL 显示BBU设计参数 MegaCli -AdpBbuCmd -GetBbuDesignInfo –aALL 显示当前BBU属性 MegaCli -AdpBbuCmd -GetBbuProperties –aALL 查看充电状态 MegaCli -AdpBbuCmd -GetBbuStatus -aALL |grep &quot;Charger Status&quot; 查看充电进度百分比 MegaCli -AdpBbuCmd -GetBbuStatus -aALL |grep &quot;Relative State of Charge&quot; 查看所有物理磁盘信息 MegaCli -PDList -aALL 显示所有逻辑磁盘组信息 MegaCli -LDInfo -LALL –aAll 查看物理磁盘重建进度(重要)MegaCli -PDRbld -ShowProg -PhysDrv [1:5] -a0 查看适配器个数 MegaCli –adpCount 查看适配器时间 MegaCli -AdpGetTime –aALL 显示所有适配器信息 MegaCli -AdpAllInfo –aAll 显示RAID卡型号，RAID设置，Disk相关信息 MegaCli -cfgdsply –aALL 查询RAID阵列个数 MegaCli -cfgdsply -aALL |grep &quot;Number of DISK GROUPS:&quot; 查看Cache 策略设置 MegaCli -cfgdsply -aALL |grep Polic 查看磁盘缓存策略 # L----&gt;[VD num or ALL] a----&gt;[Adapter num or ALL] MegaCli -LDGetProp -Cache -L0 -a0 # or MegaCli -LDGetProp -DskCache -LALL -aALL 查看物理磁盘重建进度MegaCli -PDRbld -ShowProg -PhysDrv [1:5] -a0 查看Megacli的logMegaCli -FwTermLog dsply -a0 &gt; adp2.log 设置篇 创建/删除阵列# 创建一个 RAID5 阵列，由物理盘 2,3,4 构成，该阵列的热备盘是物理盘 5 MegaCli -CfgLdAdd -r5 [1:2,1:3,1:4] WB Direct -Hsp[1:5] –a0 # 创建阵列，不指定热备 MegaCli -CfgLdAdd -r5 [1:2,1:3,1:4] WB Direct –a0 # 删除阵列 MegaCli -CfgLdDel -L1 –a0 # 在线添加磁盘 # 重建逻辑磁盘组 1 , RAID 级别是5，添加物理磁盘号 1:4。 MegaCli -LDRecon -Start -r5 -Add -PhysDrv[1:4] -L1 -a0 注：重建完后，新添加的物理磁盘会自动处于重建(同步)状态，这个时候 fdisk -l是看不到阵列的空间变大的，只有在系统重启后才能看见。 查看阵列初始化信息 阵列创建完后，会有一个初始化同步块的过程，可以查看其进度。 MegaCli -LDInit -ShowProg -LALL -aALL # or 以动态可视化文字界面显示 MegaCli -LDInit -ProgDsply -LALL –aALL 查看阵列后台初始化进度MegaCli -LDBI -ShowProg -LALL -aALL # or 以动态可视化文字界面显示 MegaCli -LDBI -ProgDsply -LALL -aALL 设置磁盘缓存策略 缓存策略解释： 代码 含义 WT (Write through) WB (Write back) NORA (No read ahead) RA (Read ahead) ADRA (Adaptive read ahead) Cached - Direct - eg： MegaCli -LDSetProp WT|WB|NORA|RA|ADRA -L0 -a0 # or MegaCli -LDSetProp -Cached|-Direct -L0 -a0 # or - enable / disable disk cache MegaCli -LDSetProp -EnDskCache|-DisDskCache -L0 -a0 热备管理 创建热备 # [1:5]----&gt;[E:S] # 指定第 5 块盘作为全局热备 MegaCli -PDHSP -Set [-EnclAffinity] [-nonRevertible] -PhysDrv[1:5] -a0 # eg： MegaCli -PDHSP -Set -Dedicated -Array0 -physdrv[E:S] -a0 # 为某个阵列指定专用热备 MegaCli -PDHSP -Set [-Dedicated [-Array1]] [-EnclAffinity] [-nonRevertible] -PhysDrv[1:5] -a0 删除热备 MegaCli -PDHSP -rmv -PhysDrv[1:5] -a0 将某块物理盘下线/上线 # 下线 MegaCli -PDOffline -PhysDrv [1:4] -a0 # 上线 MegaCli -PDOnline -PhysDrv [1:4] -a0 注：如果直接删除RAID而不操作热备，其局部热备会变为全局热备，而不是删除。 管理篇 点亮指定硬盘（定位）MegaCli -PdLocate -start -physdrv[252:2] -a0 查看RAID阵列中掉线的盘MegaCli -pdgetmissing -a0 替换坏掉的模块MegaCli -pdreplacemissing -physdrv[12:10] -Array5 -row0 -a0 手动开启rebuidMegaCli -pdrbld -start -physdrv[12:10] -a0 查看Megacli的logMegaCli -FwTermLog dsply -a0 &gt; adp2.log 关闭RebuildMegaCli -AdpAutoRbld -Dsbl -a0 设置rebuild的速率MegaCli -AdpSetProp RebuildRate -30 -a0 foreign 管理创建 RAID 前, 需要检测是否具有foreign配置, 如果有但此时不需要保留 RAID 时需要清除 RAID 的 foreign状态。 检测是否具有 foreign 配置MegaCli -PDlist -aALL | grep &quot;Foreign State&quot; 将标注为 Foreign 磁盘标注为unconfigrue goodMegaCli -PDMakeGood -PhysDrv[32:5] -a0 清除 foreign 配置MegaCli -CfgForeign -Scan -a0 注：一般以上两条都要执行才能清除 foreign 状态 其他磁盘状态 State (&quot;Failed&quot;, &quot;Online, Spun Up&quot;, &quot;Online, Spun Down&quot;, &quot;Unconfigured(bad)&quot;, &quot;Unconfigured(good), Spun down&quot;, &quot;Hotspare, Spun down&quot;, &quot;Hotspare, Spun up&quot; or &quot;not Online&quot;) Unsolved 扩展 RAID（加盘） MegaCli -LDRecon -Start -r1 -Add -PhysDrv[252:1] -L1 -a0 # 报错 Failed to Start Reconstruction of Virtual Drive. FW error description: The requested command has invalid arguments. Exit Code: 0x03 参见这里1 参考资料 官方资源下载-broadcom Dell – PERC/LSI MegaCLI – How to install LSIMegaRAIDSAS DELL磁盘阵列控制卡（RAID卡）MegaCli常用管理命令汇总 MegaCli命令总结 - CSDN博客 Linux下查看Raid磁盘阵列信息的方法 Megacli 常用命令]]></content>
      <categories>
        <category>教程记录</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>Linux</tag>
        <tag>RAID</tag>
        <tag>MegaCli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在搭建Hexo中遇到的问题记录]]></title>
    <url>%2Fblog%2F2017-11-18%2Fhowto-build-hexo-blog%2F</url>
    <content type="text"><![CDATA[在网络上搜索一天多才磕磕绊绊搭建好这个博客，⁄(⁄ ⁄•⁄ω⁄•⁄ ⁄)⁄ 现在把过程中遇到的坑记录一下，希望可以给之后的同学们带来帮助。 npm包管理安装太慢怎么办？ 临时使用npm --registry https://registry.npm.taobao.org install express 持久使用(更换源链接为淘宝源)npm config set registry https://registry.npm.taobao.org # 配置后可通过下面方式来验证是否成功 npm config get registry # 或者 npm info express 通过cnpm使用npm install -g cnpm --registry=https://registry.npm.taobao.org # 使用 cnpm install expresstall express 还可以参考下面这个工具: nrm —— 快速切换 NPM 源 （附带测速功能） 我有两台电脑/换电脑后如何重新发布博客？使用 Github 的branch功能建立两个分支，（如：master和hexo）设置hexo分支为默认分支，然后将博客后台配置文件全部push到该分支。master端为使用hexo d命令发布分支。 注：master分支不能当作他用，只能作为hexo发布之后使用。 可以参考下面链接配置Hexo博客从一台电脑迁移到其他电脑 - 简书 如何设置腾讯公益为404页面？以下是知乎网友给出的回答： 直接在source根目录下创建自己的404.html即可。但是自定义404页面仅对绑定顶级域名的项目才起作用。 经我试验并不一定要绑定顶级域名才可以，使用官方给出的方案设置后并不能实现错误页 页面跳转到我们设置的 404 页面。以下来自github网友在issues中的解释： 你的站点(编注：二级域名即Github)启用了 https，腾讯公益 404 的脚本是 http 协议，因此这段脚本被阻止了。 解决的方法是将页面里的 script 换成如下： &lt;script type=&quot;text/plain&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;/&quot; homePageName=&quot;回到我的主页&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/data.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/page.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; 经试验该方法还是会出现问题，使用 F12 审查元素出现报错信息。最后使用以下方案解决该问题: 使腾讯404公益页面支持HTTPS 目前存在问题：页面会有一个卡顿加载的过程，该页面没有适配移动端。 Next主题文章页如何设置多标签？在文章发布页（MARKDOWN文件顶部）添加如下字段: title: 在搭建Hexo中遇到的问题记录 # 标签（注意短横杠后的空格） tags: - HOWTO - Hexo - Hexo-Next - etc. author: imoyao 如何给博客文章页添加音乐？可以用音乐网站的外链，但是一般外链是&lt;iframe&gt;，据说这个方法影响网站的SEO。 下面我就隆重介绍一款 HTML5 音乐播放器：Aplayer。需要用到hexo-tag-aplayer插件。 切换到本地Hexo目录，运行： npm install hexo-tag-aplayer@2.0.1 这里直接运行npm install hexo-tag-aplayer只会安装2.0.0，该版本会出现以下错误： FATAL Cannot find module &#39;/Users/hechao/Documents/TechBlog/CniceToUpp/node_modules/hexo-tag-aplayer&#39; Error: Cannot find module &#39;/Users/hechao/Documents/TechBlog/CniceToUpp/node_modules/hexo-tag-aplayer&#39; 作者给出来解决方案是用2.0.1版本。安装完成后，在需要添加音乐的地方加上： #This is a example. {% aplayer "平凡之路" "朴树" "https://xxx.com/%E5%B9%B3%E5%87%A1%E4%B9%8B%E8%B7%AF.mp3" "https://xxx.com/1.jpg" "autoplay" %} 就会出现你想要的音乐啦。 new APlayer({ element: document.getElementById("aplayer0"), narrow: false, autoplay: true, showlrc: 0, music: { title: "蓝莲花", author: "许巍", url: "http://oh6j8wijn.bkt.clouddn.com/%E8%93%9D%E8%8E%B2%E8%8A%B1.mp3", pic: "http://oh6j8wijn.bkt.clouddn.com/133107859321201106e3c3ede9a13305.jpeg", } }); ` 如果你想加入歌单，把上面的代码换成下面代码就行，参数的用法可以参照插件的使用说明。 # aplayer:删除（\`） \`{% aplayerlist %}{"narrow": false, "autoplay": true, "showlrc": 3, "mode": "random", "music": [ {"title": "平凡之路","author": "朴树","url": "http://xxx.com/%E5%B9%B3%E5%87%A1%E4%B9%8B%E8%B7%AF.mp3","pic": "https://xxx.com/1.jpg","lrc": "http://og9ocpmwk.bkt.clouddn.com/%E5%B9%B3%E5%87%A1%E4%B9%8B%E8%B7%AF.txt"}, {"title": "野子","author": "苏运莹","url": "http://xxx.com/01%20%E9%87%8E%E5%AD%90.m4a","pic": "http://xxxx.com/%E9%87%8E%E5%AD%90.jpg","lrc":"https://xxx.com/%E9%87%8E%E5%AD%90.txt"} ]}{% endaplayerlist %}\` TODOmaterial 主题填坑 参考链接 开始使用 - NexT 使用文档 GitHub+Hexo 搭建个人网站详细教程 hexo添加音乐、high一下及一些坑 | tc9011’s]]></content>
      <categories>
        <category>教程记录</category>
      </categories>
      <tags>
        <tag>HOWTO</tag>
        <tag>Hexo</tag>
        <tag>Hexo-Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中exec()和eval()的区别]]></title>
    <url>%2Fblog%2F2017-11-17%2Fexec-vs-eval-in-Python%2F</url>
    <content type="text"><![CDATA[Python 动态执行字符串代码片段（也可以是文件）， 一般会用到exec,eval。那么这两个方法有什么区别呢？ exec方法注意：exec 是一个语法声明，不是一个函数。也就是说和if、for一样。 官方文档对于exec的解释 This statement supports dynamic execution of Python code. exec的第一个表达式可以是： 代码字符串 文件对象 代码对象 tuple 前面三种情况差不多，第四种比较特殊最后讲 如果忽略后面的可选表达式,exec后面代码将在当前域执行 &gt;&gt;&gt; a=2 &gt;&gt;&gt; exec &quot;a=1&quot; &gt;&gt;&gt; a 1 如果在表达式之后使用in选项指定一个dict，它将作为global和local变量作用域 &gt;&gt;&gt; a=10 &gt;&gt;&gt; b=20 &gt;&gt;&gt; g={&#39;a&#39;:6,&#39;b&#39;:8} &gt;&gt;&gt; exec &quot;global a;print a,b&quot; in g 6 8 如果in后详指定两个表达式，它们将分别用作global和local变量作用域 &gt;&gt;&gt; a=10 &gt;&gt;&gt; b=20 &gt;&gt;&gt; c=20 &gt;&gt;&gt; g={&#39;a&#39;:6,&#39;b&#39;:8} &gt;&gt;&gt; l={&#39;b&#39;:9,&#39;c&#39;:10} &gt;&gt;&gt; exec &quot;global a;print a,b,c&quot; in g,l 6 9 10 现在说下tuple的情况，这也是导致很多人误以为exec是一个函数的原因。 如果第一个表达式是tuple exec(expr, globals) #它等效于 `exec expr in globals` exec(expr, globals, locals) #它等效于 `exec expr in globals,locals` eval()方法eval通常用来执行一个字符串表达式，并返回表达式的值。 eval(expression[, globals[, locals]]) 有三个参数，表达式字符串，globals变量作用域，locals变量作用域。 其中第二个和第三个参数是可选的。 如果忽略后面两个参数，则eval在当前作用域执行。 &gt;&gt;&gt; a=1 &gt;&gt;&gt; eval(&quot;a+1&quot;) 2 如果指定globals参数 &gt;&gt;&gt; a=1 &gt;&gt;&gt; g={&#39;a&#39;:10} &gt;&gt;&gt; eval(&quot;a+1&quot;,g) 11 如果指定locals参数 &gt;&gt;&gt; a=10 &gt;&gt;&gt; b=20 &gt;&gt;&gt; c=20 &gt;&gt;&gt; g={&#39;a&#39;:6,&#39;b&#39;:8} &gt;&gt;&gt; l={&#39;b&#39;:9,&#39;c&#39;:10} &gt;&gt;&gt; eval(&quot;a+b+c&quot;,g,l) 25 如果要严格限制eval执行，可以设置globals为__builtins__,这样 这个表达式只可以访问__builtin__ module。 # coding=utf-8 exec &#39;print(&quot;hello&quot;)&#39; #支持str的表达式动态代码执行 &gt;&gt;hello exec (&#39;a = 3*4&#39;) print a # &gt;&gt;12 b = eval(&#39;3*4&#39;) #不支持表达式 有返回值 print b # &gt;&gt;12 参考来源： python的exec、eval详解 - 疯狂奔跑的猪]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[佛与姑娘]]></title>
    <url>%2Fblog%2F2017-11-11%2Fchoose-fo-or-gril%2F</url>
    <content type="text"><![CDATA[青灯，古佛。喝酒、吃肉、泡姑娘。 我盘坐参了你这么长的时间，却总不见你发言。 你说五蕴皆空。可谁的心里总还藏着一个不穿衣服的姑娘；你说观法自在，可那姑娘夜夜钻我的被窝，又让我如何是好？ 我想了又想，还是把她办了吧。 你看这苍生万物，忙碌地生，忙碌地死。你笑他们无知无力，我仰你伟大慈悲。你关照那么多的生死，我却只关心自己的琐碎。 索性我也坦胸露乳，我也装它个四大皆空。 于是，你是不是也该教我个蒙事的法门？一念一执，念她个死心塌地，执她个执迷不悟。 管他欢乐还是痛苦，管他喜悦还是悲伤。 花间一壶酒，对着月亮喝个死去活来，摸着姑娘的大腿喃喃道：卧槽，真是难得糊涂。 糊涂着，我抱着那姑娘在床单上滚来又滚去。 你掐着手印笑而不语地看着我们手淫。 我想着等头发长长了也去烫一头如你一样五蕴皆空的头发，披上一身袈裟和姑娘拉着手私奔——也还是在你的手掌心里游荡。 说真的，如果你爱我就赶快带我离开。 其它的东西都是扯淡，扯多了你就是耍流氓。 谁说释迦老爷子不耍流氓？那是他自己说的。 我把木鱼敲碎，把蒲团坐穿，在梦里把你摸了一遍又一遍。 我脱了这身衣服就已不再是我，我穿上了衣服自己却怎么也找不到了。 一时，佛在舍卫国，破衣烂钵：“可有残羹施舍？” 一个说：“去去去，哪里来的叫花，这里人人都忙着寂寞，哪有闲工夫理你。” 佛说：“寂寞这个东西，多半是姑娘闹的。可到哪去找个姑娘，不可说，不可说。” 说到头来还是说到姑娘。 我就说寂寞就他妈是个光着大腿的姑娘，让你看着又偏偏不让你摸。 看得你心也痒痒嘴也痒痒，总憋着法地想一些污言秽语来挑逗她。 可越是挑逗她就离你越近，离你越近就越不让你摸。 我觉得，这很操蛋。 佛说，这就是法啊，你明知它是真的却总也抓不住，你分明看不到却总在你身边转。逗着你，馋着你，说一些恼人的话来勾引你，惹你生气，惹你欢喜。 我说，这分明是耍流氓。 佛说，对呀，就是耍流氓，你把恶根丢了，把执念丢了，把妄想丢了，把姑娘丢了，脱光了衣服站街上，就立地成佛了。 我脱光了衣服站在街上，来了两个漂亮的女警察问我在做什么。 我说，我立地成佛，然后度你们出苦厄。 她们非要把我抓走，我说我日你们老母！！！ 佛笑了，坐在远远的云端，莲花台上。 我说这不科学，众生太执，姑娘又太美，教人怎么度，怎么个无欲无求。 佛打了个哈欠，就没再说什么。 我觉得这有些扯，但还是耐着性子思索一些事情。 最后我决定，还是把那个勾引我的小娘们给办了。 办她个五蕴皆空，度她出寂寞的苦厄。]]></content>
      <categories>
        <category>悦读</category>
      </categories>
      <tags>
        <tag>美文</tag>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DRBD备忘记录]]></title>
    <url>%2Fblog%2F2017-09-11%2FRecord-of-drbd%2F</url>
    <content type="text"><![CDATA[这是一个关于 DRBD 的使用备忘录。 开始阅读之前，请先注意示例中使用的DRBD版本 drbdadm -V # DRBDADM_VERSION=8.4.3 注意：安装的kernel-devel的内核源码（内核源码路径/usr/src/kernel/）和当前系统的kernel版本(uname -r)不一致的话需要把当前内核更新一下。在2.6.33及以上版本的内核默认中有DRBD,之前在用的DRBD主要8.0、8.2、8.3 三个版本,对应的rpm包是drbd,drbd82和drbd83，因此需要安装对应的内核模块，对应的名字为kmod-drbd,kmod-drbd82,kmod-drbd83。由于drbd是作为内核模块进行工作的，故建议使用与内核对应的版本，对应关系如下表。 Linux releases DRBD releases 2.6.33 8.3.7 2.6.34 8.3.7 2.6.35 8.3.8 2.6.36 8.3.8.1 2.6.37 8.3.9 2.6.38 8.3.9 2.6.39 8.3.10 3.0 - 3.4 8.3.11 3.5 - 3.7 8.3.13 注意:目前官网上面8.0 – 8.3.x已标注为Deprecated即不建议使用状态。 drbd状态记录本部分内容详见此处 清除单个 DRBD 资源配置：(以drbd10为例)drbd-overview # drbd概览 drbdadm down drbd10 #down drbd echo yes|drbdadm wipe-md drbd10 #清除metadata cd /etc/drbd.d/ # 注意，此处根据drbd版本不同也可能在/usr/local/etc/drbd.d/ rm drbd10.res #删除resource文件 重启 DRBD 服务service drbd stop service drbd start DRBD扩容当遇到我们的drbd resource设备容量不够的时候，而且我们的底层设备支持在线增大容量的时候（比如lvm），我们可以先增大底层设备的大小，然后再通过drbdadm resize resource_name来实现对resource的扩容。这里有需要注意的是：只有在单主模式下可以这样做，而且需要先在两节点上都增大底层设备的容量，然后仅在主节点上执行resize命令。 在执行了resize命令后，将自动触发一次当前主节点到其他所有从节点的re-synchronization； 如果我们在drbd非工作状态下对底层设备进行了扩容，然后再启动drbd，将不需要执行resize命令（当然前提是在配置文件中没有对disk参数项指定大小），drbd自己会知道已经增大了容量； 在进行底层设备的增容操作的时候千万不要修改到原设备上面的数据，尤其是drbd的meta信息，否则有可能毁掉所有数据。 流程简单示例# 先在两端扩展Lun（需要相同大小） lvextend -Ll(50G) lvpath # drbd从端：（双主模式切换为主从模式） drbdadm secondary drbd[Num] # drbd主端： drbdadm resize drbd[Num] global_common.conf配置（示例）global { usage-count no; # 是否向官方发送统计报告（影响性能） } common { # 定义drbd设备共享的属性信息 handlers { } startup { # 启动时候的相关设置 wfc-timeout 50; become-primary-on both; # 允许双主 } disk { on-io-error detach; # 配置I/O错误处理策略为分离 no-disk-flushes ; no-disk-barrier; c-plan-ahead 0; c-fill-target 24M; c-min-rate 80M; c-max-rate 720M; } net { # 网络配置相关 protocol C; # 同步异步控制（见下方介绍） after-sb-0pri discard-younger-primary; # 脑裂修复 after-sb-1pri discard-secondary; after-sb-2pri call-pri-lost-after-sb; allow-two-primaries yes; # 允许双主 max-buffers 36k; sndbuf-size 1024k ; rcvbuf-size 2048k; } syncer { # 同步相关的设置 rate 4194304k; # bytes/second al-extents 6433; } } # Read_More:http://tech.sina.com.cn/smb/2008-12-22/1050926302.shtml 数据同步协议DRBD有三种数据同步模式:同步，异步，半同步 异步：指的是当数据写到磁盘上，并且复制的数据已经被放到我们的tcp缓冲区并等待发送以后，就认为写入完成； 半同步：指的是数据已经写到磁盘上，并且这些数据已经发送到对方内存缓冲区，对方的tcp已经收到数据，并宣布写入； 同步：指的是主节点已写入，从节点磁盘也写入； DRBD的复制模型是靠protocol关键字来定义的：protocol A表示异步；protocol B表示半同步；protocol C表示同步，默认为protocol C。 在同步模式下只有主、从节点上两块磁盘同时损害才会导致数据丢失。在半同步模式下只有主节点宕机，同时从节点异常停电才会导致数据丢失。 注意: 主从所在的磁盘分区最好大小相等,DRBD磁盘镜像相当于网络RAID1；（本人使用时强制相等，但网上没有关于分区大小是否一定要相同的确切说法） 网络同步时需要一定的时间，在同步完成之前最好不要重启，否则会重新同步； DRBD的主节点不会监控从节点的状态，所以有可能会造成数据重传； 格式化只需要在primary节点上进行,且只能在主节点上挂载；若主节点下线,从节点上线,则从节点可以直接挂载,不需要再次格式化。集群中只有primary服务器可以挂载设备，secondary挂载会报错。只有在进行故障迁移升级为主时才需要挂载。 如果DRBD状态下关机双控恢复不过来，尝试删除DRBD配置信息，然后停掉DRBD端ODSP和mysql重启之后即可；(此条仅针对公司项目) 单个drbd配置文件（以drbd10.res 为例）项目中的配置方案resource drbd11 { on controller-1 { device /dev/drbd11; disk /dev/StorPool11/SANLun11; address 192.168.2.10:57811; meta-disk internal; } on controller-2 { device /dev/drbd11; disk /dev/StorPool11/SANLun11; address 192.168.2.18:57811; meta-disk internal; } } 另外一种配置方案来自这里 resource r0 { # ① device /dev/drbd0; # ② disk /dev/sda1; # ③ meta-disk internal; # ④ on alice { # ⑤ address 192.168.1.10:7788; # ⑥ } on bob { address 192.168.1.11:7788; } syncer { rate 7M; # ⑦ } } 翻译以看懂为目的： 1.允许某些系统服务项关联的名称，如：nfs, http, mysql_0, postgres_wal等；Name that allows some association to the service that needs them. For example, nfs, http, mysql_0, postgres_wal, etc. 2.DRBD设备名称及编号；The device name for DRBD and its minor number. 在上面的例子中，drbd的编号是0。udev集成脚本提供符号链接/dev/drbd/by-res/nfs/0。或者，也可以省略配置中的设备节点名称，然后使用下面这种形式代替：drbd0 minor 0（/dev/可选）或/dev/drbd0； In the example above, the minor number 0 is used for DRBD. The udev integration scripts will give you a symbolic link /dev/drbd/by-res/nfs/0. Alternatively, omit the device node name in the configuration and use the following line instead:drbd0 minor 0 (/dev/ is optional) or /dev/drbd0 3.节点之间进行复制的原始设备。注意：在本例中，两个节点上面的设备是相同的。若使用不同设备，请将磁盘参数移动到主机上。（？） The raw device that is replicated between nodes. Note, in this example the devices are the same on both nodes. If you need different devices, move the disk parameter into the on host. 4.meta-disk参数通常包含隐式值，但是你也可以指定一个显式设备保存元数据。详情参见：这里&gt;&gt;&gt; The meta-disk parameter usually contains the value internal, but it is possible to specify an explicit device to hold the meta data. See http://www.drbd.org/users-guide-emb/ch-internals.html#s-metadata for more information. 5.on节配置指明改配置应用于具体哪个host。 The on section states which host this configuration statement applies to. 6.各节点的IP地址和端口号。每个资源需要一个单独的端口，通常以7788开始。 The IP address and port number of the respective node. Each resource needs an individual port, usually starting with 7788. 7.同步率。将其设置为磁盘读写和网络带宽的三分之一。仅限制重新同步，而不是复制。 The synchronization rate. Set it to one third of the lower of the disk- and network bandwidth. It only limits the resynchronization, not the replication. 主从切换主备节点切换有两种方式，分别是停止DRBD服务切换和正常切换。 正常切换主切换成从，需要先卸载文件系统，再执行降级为从的命令 主端umount /data/ drbdadm secondary all 从端从切换成主，要先执行升主的命令，然后挂载文件系统 drbdadm primary all mount /dev/drbd0 /data/ 停止drbd服务切换基本思路：关闭主节点服务，此时挂载的DRBD分区就自动在主节点卸载了，然后在备用节点执行切换命令 [root@drbd2 ~]#drbdadm primary all # 此时报错： 2: State change failed: (-7) Refusing to be Primary while peer is not outdated Command &#39;drbdsetup 2 primary&#39; terminated with exit code 11 # 因此，必须在备用节点执行如下命令： [root@drbd2 ~]#drbdsetup /dev/drbd0 primary –o # 或者 [root@drbd2~]#drbdadm -- --overwrite-data-of-peer primary all 当在备用节点执行切换到主节点命令后，原来的主用节点自动变为备用节点。无需在主用节点再次执行切换到备用节点的命令。 脑裂修复当DRBD出现脑裂后，会导致DRBD两边的磁盘数据不一致，在确定要作为从的节点上切换成secondary，并放弃该资源的数据: drbdadm secondary r0 drbdadm -- --discard-my-data connect r0 然后作为primary的节点重新连接secondary（如果这个节点当前的连接状态为WFConnection的话，可以省略），使用如下命令连接： drbdadm connect r0 其他双控配置互信（假定在控1执行）echo y|ssh-keygen -t dsa -f ~/.ssh/id_dsa -N &quot;&quot; cp ~/.ssh/id_dsa.pub ~/.ssh/authorized_keys scp -r ~/.ssh controller-2: #双控对端hostname 参考阅读 官方手册 SUSE高可用配置 使用DRBD实现复制存储 drbd 配置 - Rikewang - 博客园 CentOS下实现Heartbeat+DRBD+MySQL双机热备硬件故障自动切换高可用(HA)方案 | 三木的人生——3mu.me High availability with the Distributed Replicated Block Device 记一次DRBD Unknown故障处理过程 DRBD 管理、故障处理部分(https://www.linuxidc.com/Linux/2013-12/93422.htm) DRBD编译安装中出现的问题及解决小结 - CSDN博客 DRBD配置参数]]></content>
      <categories>
        <category>教程记录</category>
      </categories>
      <tags>
        <tag>DRBD</tag>
        <tag>存储</tag>
        <tag>集群</tag>
      </tags>
  </entry>
</search>
